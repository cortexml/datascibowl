#+DRAWERS: HIDDEN

* DONE Setup
  CLOSED: [2014-12-24 Wed 13:45]
  :LOGBOOK:  
  - State "DONE"       from ""           [2014-12-24 Wed 13:45]
  :END:      
  - create a data directory
  - create a file and put in it the download links
#+begin_src sh :results verbatim raw replace   
  projdir="$HOME/projects/2014-12-20_datascibowl/"
  if [ -d "$projdir" ]
  then
    echo "$projdir exists, entering it"
    cd "$projdir"
  else
    echo "making $projdir and entering it"
    mkdir "$projdir" && cd "$_"
  fi
  if [-d "data"]
  then
    echo "data dir exists, entering it"
    cd "data"
  else
    echo "creating data directory and download file list"  
    mkdir "data" && cd "data"
    data_download.txt
    echo 'http://www.kaggle.com/c/datasciencebowl/download/train.zip' > data_download.txt
    echo 'http://www.kaggle.com/c/datasciencebowl/download/test.zip' >> data_download.txt
  fi
#+end_src
#+RESULTS:
/home/joth/projects/2014-12-20_datascibowl/ exists, entering it
creating data directory and download file list


* DONE Get data
  CLOSED: [2014-12-24 Wed 13:45]
  :LOGBOOK:  
  - State "DONE"       from ""           [2014-12-24 Wed 13:45]
  :END:      
#+begin_src sh silent
  # currently doesn't work, need to export browser cookies
  # and use wget option --load-cookies
  # http://askubuntu.com/questions/161778/how-do-i-use-wget-curl-to-download-from-a-site-i-am-logged-into
  # only if files in data_download dont exist
  cd "$HOME/projects/2014-12-20_datascibowl/data"
  wget -nv -i data_download.txt
#+end_src
#+RESULTS:

#+begin_src sh silent
  # again if they dont already exist, that's -n
  cd ~/projects/2014-12-20_datascibowl/data
  unzip -n train
  unzip -n test
#+end_src


* DONE Ipython
  CLOSED: [2014-12-20 Sat 22:03]
  :LOGBOOK:  
  - State "DONE"       from "TODO"       [2014-12-20 Sat 22:03]
  :END:      
  - installed in arch, had a few dependencies, some from
    AUR I think, though that may have been for skimage
  ~ipython2 notebook~ 
  - opens ipython in web browser
  - from Help can see keyboard shortcuts, and links to
    libary documentation


* TODO Python/Dev Stuff [8/9]
** DONE Setup packages
   CLOSED: [2014-12-24 Wed 13:45]
   :LOGBOOK:  
   - State "DONE"       from ""           [2014-12-24 Wed 13:45]
   :END:      
   - python environment in [[http://antarch.calepin.co/setting-up-a-python-environment-in-arch-linux-basics.html][arch]]
   - it is suggested to manage packages with the distro
     package manager [[http://antarch.calepin.co/setting-up-a-python-environment-in-arch-linux-basics.html][see]]
   - from the [[http://nbviewer.ipython.org/github/udibr/datasciencebowl/blob/master/141215-tutorial.ipynb][tutorial]] it looks like we need
   - 2.7
     - extra
       - [X] sklearn scikit-learn
       - [X] matplotlib
       - [X] pylab
       - [X] numpy
       - [X] pandas
       - [X] scipy
       - [X] pillow
       - there were some more dependencies for iptyhon, and
         one more for a function called from the tutorials
       - imread was one of them
       - 
     - defaults
       - glob
       - os
       - warnings
       - pylab in venv
     - needed gcc-fortran for install scipy in venv

** DONE virtual env Research
   CLOSED: [2014-12-23 Tue 01:24] SCHEDULED: <2014-12-22 Mon>
   :LOGBOOK:  
   - State "DONE"       from "TODO"       [2014-12-23 Tue 01:24]
   :END:      
   - 
** DONE Setting up for python development on ArchLinux
    CLOSED: [2014-12-24 Wed 13:44]
    :LOGBOOK:  
    - State "DONE"       from "NEXT"       [2014-12-24 Wed 13:44]
    - State "NEXT"       from ""           [2014-12-24 Wed 12:47]
    :END:      
    - References
      - [[http://docs.python-guide.org/en/latest/dev/virtualenvs/][pydocs]]
      - [[https://wiki.archlinux.org/index.php/Python_VirtualEnv][archwiki]]

First we're going to isntall pip and virtual env, we dont
need pip as venvs install pip into the venv when created,
but worth getting it for shell completion.
#+begin_src sh :noeval
sudo pacman -S python3-pip
sudo pacman -S python3-virtualenv
# sudo pacman -S python2-pip
# sudo pacman -S python2-virtualenv
#+end_src

Make pip play nice with zsh.
#+begin_src sh
pip completion --zsh >> ~/.zprofile
#+end_src

venvwrapper is a nubmer of shell scripts that simplify
working with and tracking venvs. I regret it fixes the
virtual env base path, which affects how I organize
projects. Although venvs can be linked to [[https://virtualenvwrapper.readthedocs.org/en/latest/projects.html][project directory]]
using mkproject, which satisfies my purposes.
#+begin_src python :noeval
#sudo pip install virtualenvwrapper
sudo pacman -S python-virtualenvwrapper # can create python2 venvs
echo "source /usr/local/bin/virtualenvwrapper.sh" >> ~/.zprofile
export WORKON_HOME=~/venvs
export PROJECT_HOME=~/projects
mkdir -p $WORKON_HOME
echo "export WORKON_HOME=$WORKON_HOME" >> ~/.zprofile
echo "export PROJECT_HOME=$PROJECT_HOME" >> ~/.zprofile
#+end_src

Head over to the project directory and setup a venv there,
then activate it.
#+begin_src sh :noeval
#virtualenv -p /usr/bin/python2.7 workspace_datascibowl
# mkvirtualenv -p /usr/bin/python2.7 2014-12-23_datascibowl

# -f makes the venv even if proj exists
mkproject -f -p /usr/bin/python2.7 2014-12-24_testdatascibowl

# check out your venvs
ls $WORKON_HOME
#+end_src

#+begin_src sh
pip install git://github.com/yajiemiao/pdnn
# check out packages in venv
lssitepackages
#+end_src

~deactivate~ deactivates the current venv. And can also
navigate to the active venv with ~cdvirtualenv~.

** DONE Settung up python dev on ArchLinux v2
   CLOSED: [2015-01-06 Tue 22:04]
   :LOGBOOK:  
   - State "DONE"       from "NEXT"       [2015-01-06 Tue 22:04]
   - State "NEXT"       from "TODO"       [2015-01-06 Tue 08:34]
   :END:      
   - missed the point, mkproject not working, it's putting
     the venv in the project dir instead of the $WORKON_HOME
   - retested - mkproject works
   - for future reference, this is how to do this if there's
     alredy a project dir
   - so how to do this? just make the venv and then
     associate it with a project dir?
#+begin_src sh :noeval
mkvirtualenv -p /usr/bin/python2.7 2014-12-20_datascibowl
setvirtualenvproject  ~/projects/2014-12-20_datascibowl
#or 
mkvirtualenv -p /usr/bin/python2.7 -a ~/projects/2014-12-20_datascibowl  2014-12-20_datascibowl 
cdvirtualenv # takes to venv dir
cdproject # takes to project dir of active venv
#+end_src

** DONE setting up venv for distribution
   CLOSED: [2015-01-06 Tue 22:44]
   :LOGBOOK:  
   - State "DONE"       from "NEXT"       [2015-01-06 Tue 22:44]
   - State "NEXT"       from ""           [2015-01-06 Tue 22:43]
   :END:      
   - make requirements list

#+begin_src sh :noeval
pip freeze > ~/venvs/2014-12-20_datascibowl/requirements.txt
#+end_src

#+begin_src sh
cat $WORKON_HOME/2014-12-20_datascibowl/requirements.txt
#+end_src

#+RESULTS:
| Jinja2==2.7.3                         |
| MarkupSafe==0.23                      |
| Pillow==2.7.0                         |
| backports.ssl-match-hostname==3.4.0.2 |
| certifi==14.05.14                     |
| ipython==2.3.1                        |
| matplotlib==1.4.2                     |
| mock==1.0.1                           |
| nose==1.3.4                           |
| numpy==1.9.1                          |
| pandas==0.15.2                        |
| pyparsing==2.0.3                      |
| python-dateutil==2.4.0                |
| pytz==2014.10                         |
| pyzmq==14.4.1                         |
| scikit-image==0.10.1                  |
| scikit-learn==0.15.2                  |
| scipy==0.14.1                         |
| six==1.9.0                            |
| tornado==4.0.2                        |
| wsgiref==0.1.2                        |

   - pip install -r 
   - ipython
   - pyzmq
   - jinja2
   - tornado

** DONE [[https://docs.python.org/2/library/pickle.html][Pickle]] for saving python binary objects 
   CLOSED: [2015-01-09 Fri 21:18]
   :LOGBOOK:  
   - State "DONE"       from "NEXT"       [2015-01-09 Fri 21:18]
   - State "NEXT"       from "TODO"       [2015-01-06 Tue 13:49]
   - State "NEXT"       from "TODO"       [2015-01-06 Tue 13:37]
   :END:      
*** why pickle?
    Pickle lets you make persistent python objects.
    Intermediate results, such as feature matrices and model
    objects, may be costly to compute. It is often useful
    then to save them. This may also aid reproduction.
    Pickle allows for this by converting python objects to
    byte streams.

*** what can pickle do?
    Pickle pickles (serializes) python objects into byte
    streams. It also unpicks (or unserializes) them, i.e.
    the byte stream is loaded back into a python object. The
    byte streams can be saved to persistent storage, in a
    database, or transmitted over a network.

    If you know the nitty gritty send me a link at the
    contact page, twitter, or leave a comment.

*** What can't be pickled?
    Generally speaking, classes, functions, and methods. 

*** how to use it?
    For pickling (unpickling), create a pickle object and
    call its dump (load) method with a file connection.

#+begin_src python :results none  
import pickle

wrc_champions = {
  "Sebastien Loeb": [i+2004 for i in range(9)],
  "Juha Kankkunen": [1986,1987,1991,1993]
}

with open("wrc_champions.p", "w") as f:
  pickle.dump(wrc_champions, f)

#+end_src



#+begin_src python :results verbatim org replace output 
import pickle
import pprint
import os
with open("wrc_champions.p") as f:
  wrc_champions = pickle.load(f)

pprint.pprint(wrc_champions)
os.remove("wrc_champions.p")
#+end_src

#+RESULTS:
#+BEGIN_SRC org
{'Juha Kankkunen': [1986, 1987, 1991, 1993],
 'Sebastien Loeb': [2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012]}
#+END_SRC

*** cPickle
    The cPickle module has Pickler and Unpickler methods,
    which are up to 1000 times faster than the Pickle
    counterparts. I wonder what the limitations are to that.
    Although, cPickle ones can't be [[https://docs.python.org/2/library/pickle.html#pickle-sub][subclassed]], they suit
    most common purposes. There are [[https://wiki.python.org/moin/UsingPickle][other reasons]] to stick
    with pickle, though.

*** Caveats (Carrots?)
    Dont eat pickles from untrusted sources, arbitrary
    python code can be executed in unpickling! Found [[https://wiki.python.org/moin/UsingPickle][here]],
    along with more pertinents.

** DONE Sets and lists [[https://docs.python.org/2/tutorial/datastructures.html][builting data structures]]
    CLOSED: [2014-12-24 Wed 20:50]
    :LOGBOOK:  
    - State "DONE"       from ""           [2014-12-24 Wed 20:50]
    :END:      
Sets are hashed iterable unorder lists of distinct items.
#+begin_src python :results scalar org replace output  
a = ["why'd", "you", "crisp", "greedo?"]
set_a = set(a)
type(a)
type(set_a)

print "List a:"
for item in a:
  print item

print "Set a:"
for item in set_a:
  print item

a.append(", han")
print a

set_b = (["why'd", "you", "crisp", "greedo?"])
print set_a.difference(set_b)
#+end_src

#+RESULTS:
#+BEGIN_SRC org
List a:
why'd
you
crisp
greedo?
Set a:
you
crisp
greedo?
why'd
["why'd", 'you', 'crisp', 'greedo?', ', han']
set(['you', 'crisp', 'greedo?', "why'd"])
#+END_SRC
** DONE list comprehensions
   CLOSED: [2015-01-09 Fri 21:21]
   :LOGBOOK:  
   - State "DONE"       from "TODO"       [2015-01-09 Fri 21:21]
   :END:      
   - did an online python tutorial
   - dont even remember why!
** NEXT [[https://wiki.python.org/moin/Generators][generators]]
   :LOGBOOK:  
   - State "NEXT"       from "TODO"       [2015-01-09 Fri 21:21]
   :END:      
   
** learn key python packages [2/6]
   :LOGBOOK:  
   - State "DONE"       from ""           [2015-02-15 Sun 19:40]
   :END:      
   - for this i changed the python command variable in emacs
     to use python2
   - also must use :results output tag instead of :results
     value, as the latter requires you return object
*** TODO [[http://docs.scipy.org/doc/numpy/reference/][Numpy]] [2/3]
    :LOGBOOK:  
    - State "DONE"       from ""           [2014-12-21 Sun 21:14]
    :END:      
**** DONE creating arrays
     CLOSED: [2015-01-06 Tue 22:47]
     :LOGBOOK:  
     - State "DONE"       from ""           [2015-01-06 Tue 22:47]
     :END:      

#+begin_src python :results  code replace output 
import numpy as np
x = np.array([[1, 2, 3], [4, 5, 6]], np.int32)
print type(x)
print x
print x.shape
print x[0,1]
print x[1,2]
print x[:,1]
print x[:1,]
#+end_src

#+RESULTS:
#+BEGIN_SRC python
<type 'numpy.ndarray'>
[[1 2 3]
 [4 5 6]]
(2, 3)
2
6
[2 5]
[[1 2 3]]
#+END_SRC
**** DONE [[http://docs.scipy.org/doc/numpy/reference/arrays.indexing.html#arrays-indexing][slicing]]
     CLOSED: [2015-01-06 Tue 22:47]
     :LOGBOOK:  
     - State "DONE"       from ""           [2015-01-06 Tue 22:47]
     :END:      
     - is powerful, and slices are pointers, i.e. updating
       their contents updates the parent object
     - slice with array[i:j:k] where i is start index, j is
       stop, and k int > 0 is step
     - seems to be indexed as so
       |---+---+---|
       | 0 | 2 | 4 |
       | 1 | 3 | 5 |
       |---+---+---|

#+begin_src python :results  code replace output 
import numpy as np
x = np.array([[1, 2, 3], [4, 5, 6]], np.int32)
print x[1:5:2]
print x[:,1]
print x[:1,]

#+end_src

#+RESULTS:
#+BEGIN_SRC python
[[4 5 6]]
[2 5]
[[1 2 3]]
#+END_SRC

**** NEXT [[http://docs.scipy.org/doc/numpy/reference/arrays.nditer.html][iteration]]
     :LOGBOOK:  
     - State "NEXT"       from ""           [2015-01-06 Tue 22:47]
     :END:      
     - 

**** [[http://docs.scipy.org/doc/numpy/reference/routines.linalg.html][linalg]]
     - 
*** DONE [[http://docs.scipy.org/doc/numpy/reference/][Scipy]]
    CLOSED: [2015-01-04 Sun 13:18]
    :LOGBOOK:  
    - State "DONE"       from "TODO"       [2015-01-04 Sun 13:18]
    :END:      
    - mathematical functions built on numpy
    - read about it.
      - stats functions,
      - spatial data method such as delaunay triangulation,
      - singal proc
      - integration, ode
    - there is a [[http://docs.scipy.org/doc/scipy/reference/tutorial/index.html][tutorial]]
*** NEXT [[http://docs.scipy.org/doc/scipy/reference/tutorial/ndimage.html][multidimensional image proc]]
    :LOGBOOK:  
    - State "NEXT"       from "TODO"       [2015-01-09 Fri 21:22]
    - State "NEXT"       from "TODO"       [2015-01-09 Fri 21:22]
    - State "NEXT"       from "TODO"       [2015-01-09 Fri 21:22]
    - State "NEXT"       from "TODO"       [2015-01-09 Fri 21:21]
    :END:      
    - i dont think
    - relevant for snodrofo
*** NEXT Pandas
    :LOGBOOK:  
    - State "NEXT"       from "TODO"       [2015-01-09 Fri 21:22]
    :END:      
    - 
*** DONE [[http://scikit-learn.org/stable/user_guide.html#user-guide][sci kit learn (user guide)]]
    CLOSED: [2015-01-06 Tue 08:36]
    :LOGBOOK:  
    - State "DONE"       from "TODO"       [2015-01-06 Tue 08:36]
    :END:      
    - the [[http://scikit-learn.org/stable/modules/linear_model.html][help section on regression]] is easy as i already
      understand that, understanding the python part is
      straight forward
    - and the [[http://scikit-learn.org/stable/tutorial/machine_learning_map/index.html][algorithm map]] is very useful
*** NEXT sci kit image
    :LOGBOOK:  
    - State "NEXT"       from "TODO"       [2015-01-09 Fri 21:22]
    :END:      
    - 
** Hu central moment expirimentation [0/2]
   :LOGBOOK:  
   - State "DONE"       from "CANCELLED"  [2015-02-15 Sun 19:40]
   - State "CANCELLED"  from "TODO"       [2015-02-05 Thu 12:50] \\
     - dnn
   :END:      
*** TODO Features [1/2]
   - [X] try using moments 2-6, I htink 1-7 are not as
     meaninful
     - no better
   - [ ] try permutation of the central moments combinations

*** NEXT Tests [0/1]
    :LOGBOOK:  
    - State "NEXT"       from ""           [2015-01-06 Tue 08:35]
    :END:      
   - [ ] try manually doing the central moments on a trivial
     image to test the reflect, translation, rotation
     invariance

** ML procedure
   :LOGBOOK:  
   - State "NEXT"       from ""           [2015-01-09 Fri 22:52]
   :END:      
   - read data
   - save pickled raw data? maybe with cpickle
   - calculate features and create descriptive stats on them
   - save feature matrices
   - fit models
** model infrastructure
   - how can we optimize the iteration
   - save intermediate models with pickle
   - bert is doing this
** Write a class for this? work with bert
   - ugh, i like the functional/R paradigm of methods belong
     to functions! this hurts my brain
   - inside venv we shoudl have all we need to work on it,
     including the data and libraries
   - class is datascibowl
   - attributes
     - training classes
       - nested dict with names of classes/subclasses?
   - methods
     - scale image
     - calculate feature
     - preprocess
     - 


* CANCELLED ML Stuff
  :LOGBOOK:  
  - State "CANCELLED"  from "TODO"       [2015-02-15 Sun 19:42] \\
    - sticking with pylearn
  :END:      
** TODO [[http://ufldl.stanford.edu/wiki/index.php/UFLDL_Tutorial][ufldl tutorial]] for deep learning
   - 
** DONE Check the kaggle handwriting competition example
   CLOSED: [2015-01-04 Sun 12:39] SCHEDULED: <2014-12-26 Fri>
   :LOGBOOK:  
   - State "DONE"       from "NEXT"       [2015-01-04 Sun 12:39]
   - State "NEXT"       from "TODO"       [2014-12-25 Thu 16:25]
   :END:      
   - bert thinks may be some inspiration here
   - I am not seeing much other than tutorial/info on RF
     classifier
   - RF decision trees

** CANCELLED make a uniform probability prediction
   SCHEDULED: [2014-12-26 Fri]
   :LOGBOOK:  
   - State "CANCELLED"  from "NEXT"       [2015-01-04 Sun 12:39] \\
     trivial
   - Rescheduled from "2014-12-22 Mon" on [2014-12-25 Thu 16:29]
   - State "NEXT"       from "TODO"       [2014-12-21 Sun 21:13]
   :END:      
   The idea here is just to learn a bit more about the data
   manipulations, processing, etc in python.
   Cancelled - trivial.
*** data
    - submission of form
    | imagefilename | class1 prob | class2 prob | ... | classn prob |
    | 1.jpg         | 1/n         | 1/n         | 1/n | 1/n         | 
** NEXT Understand the error/performance measure better
   - 
** TODO Preprocessing
   - we have to identify our features, at the same time as
     not introducing some censorship of the dater
   - tutorial uses
     - thresholding on mean to reduce noise
     - dilate to connect neighboring pixels
     - segmention of connection regions - calculate their
       labels (e.g. region 1,2,3)
     - apply the labels to original images
*** NEXT check prportion of obs with maxRegion [/]
    :LOGBOOK:  
    - State "NEXT"       from "TODO"       [2015-01-09 Fri 22:52]
    :END:      
    - when no maxregion, axis region ratio is 0, same with
      hu centres for now
    - [ ] get the proportion which are 0
** TODO feature brainstorming
   - Recall, manual feature selection is a difficult
     endeavour, rather search the feature space and have a
     generalization to create features, e.g. hu moments and
     thier interactions
   - aspect ratio
   - eccentricity
   - something about the protrusions
   - how about degree of transparency/variance of pixel
     values in feature
   - most of these i reckon are captured by the hu moments
*** DONE hu central moments Research
    CLOSED: [2015-01-04 Sun 21:14] SCHEDULED: <2014-12-25 Thu>
    :LOGBOOK:  
    - State "DONE"       from ""           [2015-01-04 Sun 21:14]
    :END:      
    - and see [[Hu%20central%20moment%20expirimentation][Hu central moment expirimentation]] for tests to
      try
    - see the wiki [[http://en.wikipedia.org/wiki/Image_moment][here]]
    - image moments are certain averages of image pixel
      intensities, and functions of such first moments
    - this is defined for discrete greyscale data as

\begin{equation}
  M_{ij} = \sum_x \sum_y x^i y^j I(x,y)
\end{equation}

    - they usually are formulated to have an attractive
      property, e.g. the hu central moments are rotation,
      translation

:HIDDEN:
\begin{equation}
   I_1 = \eta_{20} + \eta_{02}
\end{equation}
\begin{equation}
   I_2 = (\eta_{20} - \eta_{02})^2 + 4\eta_{11}^2
\end{equation}
\begin{equatio}
   I_3 = (\eta_{30} - 3\eta_{12})^2 + (3\eta_{21} - \eta_{03})^2
\end{equation}
\begin{equatio}
   I_4 = (\eta_{30} + \eta_{12})^2 + (\eta_{21} + \eta_{03})^2
\end{equation}
\begin{equatio}
   I_5 = (\eta_{30} - 3\eta_{12}) (\eta_{30} + \eta_{12})[ (\eta_{30} + \eta_{12})^2 - 3 (\eta_{21} + \eta_{03})^2] + (3 \eta_{21} - \eta_{03}) (\eta_{21} + \eta_{03})[ 3(\eta_{30} + \eta_{12})^2 -  (\eta_{21} + \eta_{03})^2]
\end{equation}
\begin{equatio}
   I_6 =  (\eta_{20} - \eta_{02})[(\eta_{30} + \eta_{12})^2 - (\eta_{21} + \eta_{03})^2] + 4\eta_{11}(\eta_{30} + \eta_{12})(\eta_{21} + \eta_{03})
\end{equation}
\begin{equatio}
   I_7 = (3 \eta_{21} - \eta_{03})(\eta_{30} + \eta_{12})[(\eta_{30} + \eta_{12})^2 - 3(\eta_{21} + \eta_{03})^2] - (\eta_{30} - 3\eta_{12})(\eta_{21} + \eta_{03})[3(\eta_{30} + \eta_{12})^2 - (\eta_{21} + \eta_{03})^2].
\end{equation}
:END:

   - how does this transfer to image/pattern recognition?
     Any image can be represented as a density function in
     x,y, which can further be represented by these moments.
     these moments should be invariant with respect to the
     images position in the visual field and pattern size.
   - so *why* does the python method for getting these
     moments take a region centroid? maybe it's to mask out
     parts of the image, but in this case, where the rest of
     the image is blank, I don't see it mattering
   - so, of these moments, 7 may be bad as it represents
     reflected images, and 1, the centroid, I don't think is
     pertinent
   - what of the others? the original [[http://www.sci.utah.edu/~gerig/CS7960-S2010/handouts/Hu.pdf][ieee transactions]]
     document
   - regardless, my question is, if i add crappy features,
     why is the classifier using them and scoring so
     poorly?!

*** NEXT image feature extraction
    :LOGBOOK:  
    - State "NEXT"       from "TODO"       [2015-01-06 Tue 13:40]
    :END:      
    - [[http://scikit-learn.org/stable/modules/feature_extraction.html#image-feature-extraction][link to image feat extr section]] on scikitlearn feat
      extr page
** TODO *nested model* 
   - There are many families of plankton, and there is some
     similarity with sub classes, can we capture this
   - Some of the subclasses are even the same as others, but
     from different views
     - e.g. hydromedusae partial dark vs ShapeA
     - but we still have to predict each class as given in
       the folders
** TODO Different number of samples per class
   - shall we predict smaller samples classes with less
     confidence?
   - or resample to same number?

** feature vs model selection
I tried a few features, with unexpected (poor) and otherwise
insignificant impact on the model performance

Lets consider something, about toying with features. 

#+begin_src python :results output
# https://docs.python.org/2/library/itertools.html#itertools.combinations
import itertools as iter

def count_iterable(i):
    return sum(1 for e in i)

num_vars = [x for x in range(10)]
num_combinations = {}

for vars in num_vars:
    var_list = [var for var in range(vars)]
    num_combinations[vars] = 0
    for subsets in [y for y in var_list]:
        combinations = iter.combinations(var_list, subsets)
        num_combinations[vars] += count_iterable(combinations)

print num_combinations
#+end_src

#+RESULTS:
: {0: 0, 1: 1, 2: 3, 3: 7, 4: 15, 5: 31, 6: 63, 7: 127, 8: 255, 9: 511}

There we have it, even 4 or 5 features, playing with them
manually becomes unruly.

With regression, we have some feature selection estimators,
i.e. lasso.

What about classification... decision trees should only use
the optimal split. But they'll use some split even if
there's not a good one.

So, is it more effective to begin already with the model
search? Or do we have to search the feature model space?

This already highlights the difficulty with lacking domain
knowledge. For the driver telematics I have a much better
chance and specifying a pretty full feature space, but for
plankton ID and image processing, where I know so little...
sheesh.

So, From here, given my efforts in toying with features have
been unsuccessful, my focus goes towards trying different
models and their parameter space. Then perhaps some progress
can be made here.
** hu central moments Research
   - copied from above
   - and see [[Hu%20central%20moment%20expirimentation][Hu central moment expirimentation]] for tests to
     try
   - see the wiki [[http://en.wikipedia.org/wiki/Image_moment][here]]
   - image moments are certain averages of image pixel
     intensities, and functions of such first moments
   - this is defined for discrete greyscale data as

\begin{equation}
  M_{ij} = \sum_x \sum_y x^i y^j I(x,y)
\end{equation}

   - they usually are formulated to have an attractive
     property, e.g. the hu central moments are rotation,
     translation, reflection?

:HIDDEN:
\begin{equation}
   I_1 = \eta_{20} + \eta_{02}
\end{equation}
\begin{equation}
   I_2 = (\eta_{20} - \eta_{02})^2 + 4\eta_{11}^2
\end{equation}
\begin{equatio}
   I_3 = (\eta_{30} - 3\eta_{12})^2 + (3\eta_{21} - \eta_{03})^2
\end{equation}
\begin{equatio}
   I_4 = (\eta_{30} + \eta_{12})^2 + (\eta_{21} + \eta_{03})^2
\end{equation}
\begin{equatio}
   I_5 = (\eta_{30} - 3\eta_{12}) (\eta_{30} + \eta_{12})[ (\eta_{30} + \eta_{12})^2 - 3 (\eta_{21} + \eta_{03})^2] + (3 \eta_{21} - \eta_{03}) (\eta_{21} + \eta_{03})[ 3(\eta_{30} + \eta_{12})^2 -  (\eta_{21} + \eta_{03})^2]
\end{equation}
\begin{equatio}
   I_6 =  (\eta_{20} - \eta_{02})[(\eta_{30} + \eta_{12})^2 - (\eta_{21} + \eta_{03})^2] + 4\eta_{11}(\eta_{30} + \eta_{12})(\eta_{21} + \eta_{03})
\end{equation}
\begin{equatio}
   I_7 = (3 \eta_{21} - \eta_{03})(\eta_{30} + \eta_{12})[(\eta_{30} + \eta_{12})^2 - 3(\eta_{21} + \eta_{03})^2] - (\eta_{30} - 3\eta_{12})(\eta_{21} + \eta_{03})[3(\eta_{30} + \eta_{12})^2 - (\eta_{21} + \eta_{03})^2].
\end{equation}
:END:

   - how does this transfer to image/pattern recognition?
     Any image can be represented as a density function in
     x,y, which can further be represented by these moments.
     these moments should be invariant with respect to the
     images position in the visual field and pattern size.
   - so *why* does the python method for getting these
     moments take a region centroid? maybe it's to mask out
     parts of the image, but in this case, where the rest of
     the image is blank, I don't see it mattering
   - so, of these moments, 7 may be bad as it represents
     reflected images, and 1, the centroid, I don't think is
     pertinent
   - what of the others? the original [[http://www.sci.utah.edu/~gerig/CS7960-S2010/handouts/Hu.pdf][ieee transactions]]
     document
   - regardless, my question is, if i add crappy features,
     why is the classifier using them and scoring so
     poorly?!
** python vs R
   |-------------------+------------------+---------------------------|
   | R                 | python           | notes                     |
   |-------------------+------------------+---------------------------|
   | dynamically typed | statically typed |                           |
   | caret             | scikitlearn      | sklearn better API        |
   | functional        | object oriented  | in the sense that methods |
   |                   |                  | belong to functions in R  |
   |                   |                  |                           |



* TODO Blog topics/Notes [21/35]
** DONE pylearn 2 convolutional neural networks setup
   CLOSED: [2015-02-15 Sun 20:12]
   :LOGBOOK:  
   - State "DONE"       from "TODO"       [2015-02-15 Sun 20:12]
   :END:      
*** DONE setup pylearn 2 dependencies [2/3]
    CLOSED: [2015-02-05 Thu 12:51]
    :LOGBOOK:  
    - State "DONE"       from "TODO"       [2015-02-05 Thu 12:51]
    :END:      
    - [[http://deeplearning.net/software/pylearn2/#dependencies][pylearn 2 deps docs]]

**** DONE theano, might want bleeding edge
    CLOSED: [2015-01-11 Sun 12:58]
    :LOGBOOK:  
    - State "DONE"       from "NEXT"       [2015-01-11 Sun 12:58]
    - State "NEXT"       from "DONE"       [2015-01-11 Sun 12:58]
    :END:      
     - [[http://deeplearning.net/software/theano/install.html#bleeding-edge-install-instructions][install with pip]]
     - [X] run tests
#+begin_src python :noeval
import theano
theano.test()
#+end_src
     - I'm getting issues with the nosetest. S and K instead
       of '.'. What are these? Can't find in docs.
     - S is skip.
     - K is knownfail.

**** DONE PyYAML
    CLOSED: [2015-01-11 Sun 13:19]
    :LOGBOOK:  
    - State "DONE"       from "NEXT"       [2015-01-11 Sun 13:19]
    - State "NEXT"       from "TODO"       [2015-01-11 Sun 13:00]
    :END:      
#+begin_src sh :noeval
pip install PyYAML
#+end_src

**** NEXT PIL for some image related functionality
     :LOGBOOK:  
     - State "NEXT"       from "TODO"       [2015-01-11 Sun 13:20]
     :END:      
     - 
*** DONE install pylearn2
   CLOSED: [2015-01-11 Sun 13:40]
   :LOGBOOK:  
   - State "DONE"       from "NEXT"       [2015-01-11 Sun 13:40]
   - State "NEXT"       from ""           [2015-01-11 Sun 13:36]
   :END:      
   - clone from github
   - in venv 
#+begin_src python:noeval
python setup.py develop
#+end_src

*** DONE [[https://github.com/zygmuntz/pylearn2-practice][first tutorial pylearn2 in practice]]
    CLOSED: [2015-01-11 Sun 13:58]
    :LOGBOOK:  
    - State "DONE"       from "NEXT"       [2015-01-11 Sun 13:58]
    - State "NEXT"       from ""           [2015-01-11 Sun 13:03]
    :END:      
    - https://github.com/zygmuntz/pylearn2-practice
    - it ran. that was just to verify it works!
*** DONE setup environment vars
   CLOSED: [2015-01-11 Sun 14:16]
   :LOGBOOK:  
   - State "DONE"       from "NEXT"       [2015-01-11 Sun 14:16]
   - State "NEXT"       from ""           [2015-01-11 Sun 13:00]
   :END:      
   These are used for some tutorials and test.

#+begin_src sh :noeval
export PYLEARN2_DATA_PATH=/data/lisa/data
export PATH=$PATH:???/pylearn2/scripts
#+end_src

*** DONE [[http://nbviewer.ipython.org/github/lisa-lab/pylearn2/blob/master/pylearn2/scripts/tutorials/convolutional_network/convolutional_network.ipynb][mnist tutorial]]
    CLOSED: [2015-02-15 Sun 19:44]
    :LOGBOOK:  
    - State "DONE"       from "NEXT"       [2015-02-15 Sun 19:44]
    - State "NEXT"       from ""           [2015-01-11 Sun 13:00]
    :END:      
    - ok, we know that pylearn2 is working. it'd be good to
      go through the minst tutorial and get to grips with the
      more complex yaml/data.
    - [X] get mnist
    - [X] run the tutorial

*** DONE setup pylearn2 for our data [3/3]
    CLOSED: [2015-02-15 Sun 20:09]
    :LOGBOOK:  
    - State "DONE"       from "TODO"       [2015-02-15 Sun 20:09]
    :END:      
**** DONE Overview of setting up expiriment 
    CLOSED: [2015-01-11 Sun 14:42]
    :LOGBOOK:  
    - State "DONE"       from "NEXT"       [2015-01-11 Sun 14:42]
    - State "NEXT"       from ""           [2015-01-11 Sun 14:28]
    :END:      
 [[http://deeplearning.net/software/pylearn2/yaml_tutorial/index.html#yaml-tutorial][guide]]

Pylearn2 expiriments are python objects of the type
pylearn2.train.Train. 

- a *dataset*, of type pylearn2.datasets.dataset.Dataset
- a *model*, of type pylearn2.models.model.Model
- a *training algorithm*, of type
  pylearn2.training_algorithms.training_algorithm.TrainingAlgorithm

They are setup via a yaml configuration file such as this:

:HIDDEN:
```
!obj:pylearn2.train.Train {
    "dataset": !obj:pylearn2.datasets.dense_design_matrix.DenseDesignMatrix &dataset {
        "X" : !obj:numpy.random.normal { 'size':[5,3] },
    },
    "model": !obj:pylearn2.models.autoencoder.DenoisingAutoencoder {
        "nvis" : 3,
        "nhid" : 4,
        "irange" : 0.05,
        "corruptor": !obj:pylearn2.corruption.BinomialCorruptor {
            "corruption_level": 0.5,
        },
        "act_enc": "tanh",
        "act_dec": null,    # Linear activation on the decoder side.
    },
    "algorithm": !obj:pylearn2.training_algorithms.sgd.SGD {
        "learning_rate" : 1e-3,
        "batch_size" : 5,
        "monitoring_dataset" : *dataset,
        "cost" : !obj:pylearn2.costs.autoencoder.MeanSquaredReconstructionError {},
        "termination_criterion" : !obj:pylearn2.termination_criteria.EpochCounter {
            "max_epochs": 1,
        },
    },
    "save_path": "./garbage.pkl"
}
```
:END:

It's clear we need to setup each of these components.

**** DONE vincent domoulin tutorial
     CLOSED: [2015-02-15 Sun 20:09]
     :LOGBOOK:  
     - State "DONE"       from "NEXT"       [2015-02-15 Sun 20:09]
     - State "NEXT"       from ""           [2015-01-11 Sun 16:34]
     :END:      
     - http://vdumoulin.github.io/articles/extending-pylearn2/
**** DONE Dataset
    CLOSED: [2015-02-15 Sun 20:08]
    :LOGBOOK:  
    - State "DONE"       from "NEXT"       [2015-02-15 Sun 20:08]
    - State "NEXT"       from ""           [2015-01-11 Sun 14:41]
    :END:      
The data needs to be setup. Pylearn expects it as a pylearn
data object. Useful source for thes is at
- pylearn2/pylearn2/datasets/dense_design_matrix.py
- pylearn2/pylearn2/datasets/dataset.py
- 

The first thing to note is what is required of the dataset
object.
** DONE getting the data in
   CLOSED: [2015-02-05 Thu 12:59]
   :LOGBOOK:  
   - State "DONE"       from ""           [2015-02-05 Thu 12:59]
   :END:      
Duplicate the minst data setup.

#+begin_src sh :noeval
# clone my fork of pylearn git clone git://
git branch -c datascibowl
cdproject
cp pylearn2/datasets/mnist.py pylearn2/datasets/datascibowl.py
cp pylearn2/utils/mnist-ubyte.py pylearn2/datascibowl_reader/datascibowl.py
#+end_src

The main thing to do with data for pylearn2 is to subclass
the module's data objects. In this case, we are using
denseDesignMatrix. Let's look at the relevant info from the
docstring:

#+begin_src python :noeval
class DenseDesignMatrix(Dataset):

    """

    A class for representing datasets that can be stored as a \
    dense design matrix (and optionally, associated targets).

    Parameters
    ----------
    topo_view : ndarray, optional
        Should be supplied if X is not.  An array whose first \
        dimension is of length number examples. The remaining \
        dimensions are examples with topological significance, \
        e.g. for images the remaining axes are rows, columns, \
        and channels.
    y : ndarray, optional

        Targets for each example (e.g., class ids, values to be predicted
        in a regression task).

        - 2D ndarray, data type optional:
            This is the most common format and can be used for a variety
            of problem types. Each row of the matrix becomes the target
            for a different example. Specific models / costs can interpret
            this target vector differently. For example, the `Linear`
            output layer for the `MLP` class expects the target for each
            example to be a vector of real-valued regression targets. (It
            can be a vector of size one if you only have one regression
            target). The `Softmax` output layer of the `MLP` class expects
            the target to be a vector of N elements, where N is the number
            of classes, and expects all but one of the elements to 0. One
            element should have value 1., and the index of this element
            identifies the target class.
    axes: tuple, optional
        The axes ordering of the provided topo_view. Must be some permutation
        of ('b', 0, 1, 'c') where 'b' indicates the axis indexing examples,
        0 and 1 indicate the row/cols dimensions and 'c' indicates the axis
        indexing color channels.
    y_labels : int, optional
        If y contains labels then y_labels must be passed to indicate the
        total number of possible labels e.g. 10 for the MNIST dataset
        where the targets are numbers. This will make the set use
        IndexSpace.
    """
#+end_src

So, to subclass denseDesignMatrix for the data in question,
the following are needed:

- ~topo_view~
  - an ndarray with the following format
  (examples, parameters_indicating_topological_significance)
  - where parameters_indicating_toplogical_significance
    describe the structure of the data. Rows, columns, and
    channels is given as an example. It is easy to imagine
    setting up data in 3d space and temperature x-coords,y
    coords,z coords, temperature, for example
  - this is also what will actually hold the data in the
    examples space
  - e.g. we have (n, x, y) where n are ixj matrices of pixel
    values and x,y are simply i,j respectively
  - reshaping this to (n,x,y,1) signifies that n is
    comprised of 1 value, whereas n,x,y,3 would let us use,
    e.g., RGB

- ~y~
  - targets, each row corresponds to the targets for each
    example
  - for this example, this should be an ndarray with the
    number of elements that we have classes, and all but one
    element having value 0 (i.e. each example belongs to one
    class)
  - for example, imagine we have 3 mutually exclusive
    classes to predict. ~y~ may look like
| 0 | 0 | 1 |
| 1 | 0 | 0 |
| 1 | 0 | 0 |
| 0 | 0 | 1 |
| 0 | 0 | 1 |

- ~axes~
  - permutations of (b,0,1,c) where
  - b indicates examples
  - 0,1 indicates rows/columns(i dont understand this
    convention, perhaps 0th and 1st dimension)
  - and c indicates the colors

- ~y_labels~
  - an integer containing the total number of possible
    labels, if y contains labels

** DONE DataSciBowl options [2/2]
   CLOSED: [2015-02-06 Fri 15:45]
   :LOGBOOK:  
   - State "DONE"       from ""           [2015-02-06 Fri 15:45]
   :END:      
   - [X] train and test
     - actually, test folder in data is for prediction only
     - do not use 'test'
   - [X] total number of images for start - stop
   - 
** DONE Test DataSciBowl class
   CLOSED: [2015-02-06 Fri 16:03]
   :LOGBOOK:  
   - State "DONE"       from ""           [2015-02-06 Fri 16:03]
   :END:      
   I could use the datascibowl_reader easily enough, but
   couldn't manage to test the dataset class itself.

   I tried just copying the class def to ipython and
   instantiating, but it doesnt work. Which is so odd.
   Because creating a DenseDesignMatrix works just fine.
   Wtf. For now, I'm going to move on and see about setting
   up a model.

   It was because of a bad path. Working fine now.

** DONE Model setup with pylearn2
   CLOSED: [2015-02-06 Fri 16:18]
   :LOGBOOK:  
   - State "DONE"       from ""           [2015-02-06 Fri 16:18]
   :END:      
   In the pylearn directory ~scripts/~ there are great
   tutorials. 

   With a dataset class, the next step is training a model.
   The convenient way to do this is with yaml docs. With
   some adaptation from existing examples, mine should look
   like:

#+begin_src sh :results verbatim code replace output 
cat sr_train.yaml
#+end_src
#+RESULTS:
#+BEGIN_SRC sh
!obj:pylearn2.train.Train {
    "dataset": &train !obj:pylearn2.datasets.datascibowl.DataSciBowl {
        which_set: 'train',
        start: 0,
        stop: 25000,
	},
    "model": !obj:pylearn2.models.softmax_regression.SoftmaxRegression {
        n_classes: 121,
        irange: 0.,
        nvis: 1024,
    },
    "algorithm": !obj:pylearn2.training_algorithms.bgd.BGD {
        batch_size: 5000,
        line_search_mode: 'exhaustive',
        conjugate: 1,
        monitoring_dataset:
            {
                'train' : *train,
                'valid' : !obj:pylearn2.datasets.datascibowl.DataSciBowl {
                              which_set: 'train',
                              start: 25000,
                              stop:  30336,
                          }
            },
        termination_criterion: !obj:pylearn2.termination_criteria.MonitorBased {
            channel_name: "valid_y_misclass"
        }
    },
    "extensions": [
        !obj:pylearn2.train_extensions.best_params.MonitorBasedSaveBest {
             channel_name: 'valid_y_misclass',
             save_path: "softmax_regression_best.pkl"
        },
    ],
    save_path: "softmax_regression.pkl",
    save_freq: 1
}
#+END_SRC

   There's quite a bit going on there; the dataset, model,
   and fitting algorithm are specified along with some
   information for test/validation data. Feel free to leave
   a comment if the syntax is confusing and I will try to
   clarify.

   I want to highlight that several datasets can be used to
   monitor the fitting. Their names are arbitrary. I am
   using 'train' and 'valid', where valid is just a subset
   of the classified data reserved for testing.

monitoring_dataset : Dataset or dictionary, optional

    If not specified, no monitoring is used. If specified to
    be a Dataset, monitor on that Dataset. If specified to
    be dictionary, the keys should be string names of
    datasets, and the values should be Datasets. All
    monitoring channels will be computed for all monitoring
    Datasets and will have the dataset name and an
    underscore prepended to them

** DONE Fit a model
   CLOSED: [2015-02-15 Sun 17:48]
   :LOGBOOK:  
   - State "DONE"       from "NEXT"       [2015-02-15 Sun 17:48]
   - State "NEXT"       from ""           [2015-02-06 Fri 16:37]
   :END:      
See softmax_regression.ipynb.

On first attempt I get an error.

~ValueError: Input dimension mis-match~

[[https://groups.google.com/forum/?utm_source=digest&utm_medium=email#!searchin/pylearn-users/input$20dimension$20mis-match/pylearn-users/vpSSiko0I4o/Gjuhl62TUyIJ][the google groups has seen such a thing]] before. A good next
step is to play with the batch size, and to add theano flags
~exception_verbosity=high~ and ~optimizer=fast_compile~ or
~none~ to get a trace of which pylearn call is irritating
theano.

I'm not sure where to add these.

[[http://deeplearning.net/software/theano/library/config.html][The docs]] note that theano looks at ~$HOME/.theanorc~

Write those options to that file and try again.

#+begin_src sh :noeval
echo "[global]" > /home/joth/.theanorc
echo "exception_verbosity = high" >> /home/joth/.theanorc
echo "optimizer = fast_compile" >> /home/joth/.theanorc
#+end_src

Still no success. But now with more debug info.

I tried a few modifications to the sr_train.yaml to rule out
plausible simple mistakes with no success.

Someone on the forums recommended me to try something.
[[https://groups.google.com/forum/?utm_source=digest&utm_medium=email#!topic/pylearn-users/JaOAPWlIi8w][here's]] the tread.

"One way to figure out what is happening would be to put a
breakpoint in monitor.py a bit before line 255, and check
what comes out of the data iterator (X), in particular the
shape of all elements in the tuple, and if they seem to
correspond to inputs or targets of examples in the dataset."

Let's look at the call method of monitor.py

#+begin_src python :noeval
    def __call__(self):
        """
        Runs the model on the monitoring dataset in order to add one
        data point to each of the channels.
        """

        # If the channels have changed at all, we need to recompile the theano
        # functions used to compute them
        if self._dirty:
            self.redo_theano()

        datasets = self._datasets

        # Set all channels' val_shared to 0
        self.begin_record_entry()
        for d, i, b, n, a, sd, ne in safe_izip(datasets,
                                               self._iteration_mode,
                                               self._batch_size,
                                               self._num_batches,
                                               self.accum,
                                               self._rng_seed,
                                               self.num_examples):
            if isinstance(d, six.string_types):
                d = yaml_parse.load(d)
                raise NotImplementedError()

            # need to put d back into self._datasets
            myiterator = d.iterator(mode=i,
                                    batch_size=b,
                                    num_batches=n,
                                    data_specs=self._flat_data_specs,
                                    return_tuple=True,
                                    rng=sd)

            # If self._flat_data_specs is empty, no channel needs data,
            # so we do not need to call the iterator in order to average
            # the monitored values across different batches, we only
            # have to call them once.
            if len(self._flat_data_specs[1]) == 0:
                X = ()
                self.run_prereqs(X, d)
                a(*X)

            else:
                actual_ne = 0
                for X in myiterator:
                    # X is a flat (not nested) tuple
                    self.run_prereqs(X, d)
                    a(*X)
                    actual_ne += self._flat_data_specs[0].np_batch_size(X)
                # end for X
                if actual_ne != ne:
                    raise RuntimeError("At compile time, your iterator said "
                                       "it had %d examples total, but at "
                                       "runtime it gave us %d." %
                                       (ne, actual_ne))
        # end for d

        log.info("Monitoring step:")
        log.info("\tEpochs seen: %d" % self._epochs_seen)
        log.info("\tBatches seen: %d" % self._num_batches_seen)
        log.info("\tExamples seen: %d" % self._examples_seen)
        t = time.time() - self.t0
        for channel_name in sorted(self.channels.keys(),
                                   key=number_aware_alphabetical_key):
            channel = self.channels[channel_name]
            channel.time_record.append(t)
            channel.batch_record.append(self._num_batches_seen)
            channel.example_record.append(self._examples_seen)
            channel.epoch_record.append(self._epochs_seen)
            val = channel.val_shared.get_value()
            channel.val_record.append(val)
            # TODO: use logging infrastructure so that user can configure
            # formatting
            if abs(val) < 1e4:
                val_str = str(val)
            else:
                val_str = '%.3e' % val

            log.info("\t%s: %s" % (channel_name, val_str))
#+end_src

For each dataset an iterator is set up. My work is breaking
in the comparison of the first two items the iterator
returns. It will also be useful then to look at the __next__
method for the default densedesignmatrix class and compare
it to the mnist one.

In python,

#+begin_src python :noeval
import pdb
pdb.set_trace() # at break location, on/as line 256
#+end_src

Debug learning:
:HIDDEN:
Some useful pdb commands

~(p)rint~ print a variable

~(s)tep~ to step forward one statement, whereas ~(n)ext~
will step forward a function call. If the line is not a
function call, ~s~ and ~n~ are equivalent.

~r~ continue until routine; lets you continue until the next
return, great way to escape functions if you reckon the
bug to not be present

~(q)uit~ 

~commands~ to enter literal commands, enter *end* to stop,
and n to step through the commands

And an excellent tutorial is [[https://pythonconquerstheuniverse.wordpress.com/2009/09/10/debugging-in-python/][here]]
:END:

That aside behind us, I got into the stack to check out what
the iterator is returning. ~X[0]~ are examples and ~X[1]~
should be log probabilities for each class.

#+begin_src python :noeval
(Pdb) X[0].shape
(5000, 1024)
(Pdb) X[1].shape
(1, 121)
#+end_src

~X[1]~ actually all have value 1.

Also, in ~X[0]~, the data may be degenerate. For most of the
examples, the max value is 0. This is confirmed in the raw
data.

#+begin_src python :noeval
image_mean = [np.reshape(i, (1, 1024)).mean() for i in test.X]
d = {x:image_mean.count(x) for x in image_mean}
# {0.0: 30215,
#  0.71068366555606532: 1,
#  0.72670476576861209: 1,
#  0.73890979243259802: 1, 
#  ...}
#+end_src

So something is wrong with the data.

The a(*X) call is also confusing to me. I asked again in the
google group.

...

So some time later I [[https://github.com/jo-tham/pylearn2/commit/07fb1305ce6550b866e9cef7b5d1bb742736e787][fixed the data class]]. But still getting
this error with the softmax. Urg.

So I took a look at MNIST example. 

The data is [[http://yann.lecun.com/exdb/mnist/][here]]. Downloaded to the project dir and decompress.

#+begin_src sh :results vector code replace output
cd /home/joth/projects/2014-12-20_datascibowl/data/mnist
for file in $(ls | grep .gz):
  do
    gzip -d $file
  done
ls
#+end_src
#+RESULTS:
#+BEGIN_SRC sh
t10k-images-idx3-ubyte
t10k-labels-idx1-ubyte
train-images-idx3-ubyte
train-labels-idx1-ubyte
#+END_SRC

Eventually I noticed my data is transposed. I don't think
the transpose was needed in the class initialization.

And, with those fixed, the muthafucka works. Sadly, the
performance is 10 times worse than on the minst data, which
has best misclass rate of 0.07

#+begin_src python :noeval
epochs seen:  9
time trained:  458.503871202
ave_grad_mult : 3.07640978739
ave_grad_size : 0.0578164084249
ave_step_size : 0.168970324213
test_objective : 0.269887997532
test_y_col_norms_max : 5.97236412318
test_y_col_norms_mean : 5.28605773752
test_y_col_norms_min : 4.20493453263
test_y_max_max_class : 0.999999964196
test_y_mean_max_class : 0.914368745924
test_y_min_max_class : 0.232516262448
test_y_misclass : 0.0759
test_y_nll : 0.269887997532
test_y_row_norms_max : 1.61850785481
test_y_row_norms_mean : 0.483502165396
test_y_row_norms_min : 0.0
total_seconds_last_epoch : 52.954261
train_objective : 0.255329041014
train_y_col_norms_max : 5.97236412318
train_y_col_norms_mean : 5.28605773752
train_y_col_norms_min : 4.20493453263
train_y_max_max_class : 0.999999968304
train_y_mean_max_class : 0.911166781743
train_y_min_max_class : 0.233844764224
train_y_misclass : 0.07102
train_y_nll : 0.255329041014
train_y_row_norms_max : 1.61850785481
train_y_row_norms_mean : 0.483502165396
train_y_row_norms_min : 0.0
training_seconds_this_epoch : 48.921041
#+end_src

** DONE Shuffle the observations - keep it going forward
   CLOSED: [2015-02-16 Mon 10:36]
   :LOGBOOK:  
   - State "DONE"       from "NEXT"       [2015-02-16 Mon 10:36]
   CLOCK: [2015-02-16 Mon 10:08]--[2015-02-16 Mon 10:36] =>  0:28
   - State "NEXT"       from ""           [2015-02-15 Sun 22:10]
   :END:      
   - deterministically
   - this step alone improves misclassification rate from ~1 to ~0.8
** DONE Centred observations
   CLOSED: [2015-02-16 Mon 11:41]
   :LOGBOOK:  
   - State "DONE"       from "NEXT"       [2015-02-16 Mon 11:41]
   - State "NEXT"       from ""           [2015-02-16 Mon 11:10]
   :END:      
   - this also improves misclass from about .75 to .65
   - probably worth keeping
** DONE Try SGD
   CLOSED: [2015-02-16 Mon 17:07]
   :LOGBOOK:  
   - State "DONE"       from "NEXT"       [2015-02-16 Mon 17:07]
   CLOCK: [2015-02-16 Mon 16:33]--[2015-02-16 Mon 17:07] =>  0:34
   - State "NEXT"       from ""           [2015-02-16 Mon 16:30]
   :END:      
   Module for performing batch gradient methods.
   Technically, SGD and BGD both work with any batch size,
   but SGD has no line search functionality and is thus best
   suited to small batches, while BGD supports line searches
   and thuse works best with large batches.

   [[http://deeplearning.net/software/pylearn2/library/train.html#module-pylearn2.training_algorithms.sgd][link]]
   [[deeplearning.net/software/pylearn2/library/train.html#module-pylearn2.training_algorithms.sgd][proper link]]

   How does this compare to BGD.
   :HIDDEN:
   class pylearn2.training_algorithms.bgd.BGD(
       cost=None, 
       batch_size=None, 
       batches_per_iter=None, 
       updates_per_batch=10, 
       monitoring_batch_size=None, 
       monitoring_batches=None, 
       monitoring_dataset=None, 
       termination_criterion=None, 
       set_batch_size=False, 
       reset_alpha=True, 
       conjugate=False, 
       min_init_alpha=0.001, 
       reset_conjugate=True, 
       line_search_mode=None, 
       verbose_optimization=False, 
       scale_step=1.0, 
       theano_function_mode=None, 
       init_alpha=None, 
       seed=None)
   class pylearn2.training_algorithms.sgd.SGD(
       learning_rate, 
       cost=None, 
       batch_size=None, 
       monitoring_batch_size=None, 
       monitoring_batches=None, 
       monitoring_dataset=None, 
       monitor_iteration_mode='sequential', 
       termination_criterion=None, 
       update_callbacks=None, 
       learning_rule=None, 
       set_batch_size=False, 
       train_iteration_mode=None, 
       batches_per_iter=None, 
       theano_function_mode=None, 
       monitoring_costs=None, 
       seed=[2012, 10, 5])
   :END:
   Basically, in terms of parameters, we now have to choose
   a learning rate.

   Bottou suggest expirimenting with different rates on
   small samples. This is a research topic on its own.

   I tried learning rates of 0.01 and 0.001 with 128 batch size.

   This is muuuuuch faster than BGD.

   But got better results with BGD (i.e. misclass rate of
   0.8x with SGD).

** DONE Get predictions on training set
   CLOSED: [2015-02-16 Mon 20:50]
   :LOGBOOK:  
   - State "DONE"       from "NEXT"       [2015-02-16 Mon 20:50]
   - State "NEXT"       from "TODO"       [2015-02-16 Mon 20:50]
   - State "NEXT"       from "WAITING"    [2015-02-15 Sun 22:17]
   - State "NEXT"       from ""           [2015-02-15 Sun 22:17]
   :END:      
   :HIDDEN:
   - so following the [[http://fastml.com/how-to-get-predictions-from-pylearn2/][fastml]], it's pretty easy to setup
     predictions, see
     http://localhost:8888/notebooks/predict_tests.ipynb or below

#+begin_src python :noeval
import theano
from pylearn2.utils import serial

model_path = 'softmax_regression_best_shuf_ctr_03.pkl'
model = serial.load( model_path )

X = model.get_input_space().make_theano_batch()
Y = model.fprop( X )

# Y = T.argmax( Y, axis = 1 ) # if binary clsasification
f = theano.function( [X], Y )
y = f( x_test )
#+end_src

   - it's simply a matter of getting x_test in ther
   - this can be done by modifying the datascibowl_reader slightly
   - for now I can test it on the training data in the ipy notebook
   - good news is, class probs are predicted for each observation

** DONE Setup validation set for prediction
   CLOSED: [2015-02-17 Tue 08:43]
   :LOGBOOK:  
   - State "DONE"       from "NEXT"       [2015-02-17 Tue 08:43]
   - State "NEXT"       from ""           [2015-02-16 Mon 20:46]
   :END:      
   - could setup a function/class to writie the output data
   - basically use what's in
     http://localhost:8888/notebooks/test_data_setup_for_pred.ipynb
   - in place of the per directory image fiel reading in the
     DataSciBowl_Reader class and save to a .pkl
   - predict on the np array with the good BGD softmax
*** Saving large pickle/h5
    - doesn't work
    - get numexpr Cython and tables, hdf5 from package manager
    - then see
      http://www.shocksolution.com/2010/01/storing-large-numpy-arrays-on-disk-python-pickle-vs-hdf5adsf/
    - which works nicely
#+begin_src python :noeval
import tables
h5file = tables.openFile('test.h5', mode='w', title="Test Array")
root = h5file.root
h5file.createArray(root, "test", a)
h5file.close()
#+end_src

** DONE Get predictions on validation set and submit
   CLOSED: [2015-02-17 Tue 22:47]
   :LOGBOOK:  
   - State "DONE"       from "NEXT"       [2015-02-17 Tue 22:47]
   - State "NEXT"       from ""           [2015-02-16 Mon 20:53]
   :END:      
   - https://groups.google.com/forum/#!searchin/pylearn-users/predict/pylearn-users/d2WUUdA2_go/G73pGmWqm38J
   - For mlp, this extends my simple example
     - https://github.com/lisa-lab/pylearn2/blob/master/pylearn2/scripts/mlp/predict_csv.py
     - just use classification prediction with float and row
       names (row names being the image file name)
   - make sure data preprocessed with same settings as the
     model was used to fit!! e.g. size, center

** DONE Implement the classifier cost function in monitoring [3/3]
   CLOSED: [2015-02-21 Sat 22:48]
   :LOGBOOK:  
   - State "DONE"       from "NEXT"       [2015-02-21 Sat 22:48]
   CLOCK: [2015-02-19 Thu 20:40]--[2015-02-19 Thu 20:40] =>  0:00
   :END:      
Summary: Theano is cool. Read carefully. I will use the
builtin NLL since mine may be comparitively slow. So forget
the multiclass log loss branch.

From ian goodfellow on google groups, there are a few options:

-Write a TrainExtension that adds one by calling Monitor.add_channel
-Subclass Model and override get_monitoring_channels
-Subclass Cost and override get_monitoring_channels

If you're interested in modifying the library itself, it
could be a good idea to make ModelExtensions support adding
monitoring channels to the model's default
get_monitoring_channels return value.

So, at /pylearn2/train_extensions there is an example of a
channel added, roc_auc, which I will use as reference.

*** DONE Test usage of extra monitoring channels via extensions
    CLOSED: [2015-02-19 Thu 07:57]
    :LOGBOOK:  
    - State "DONE"       from ""           [2015-02-19 Thu 07:57]
    :END:      

First I will simply try using that channel in a monitor. See
the example in ~sr_train_07.yaml~. It simply adds the following

#+BEGIN_SRC sh :noeval
    extensions: [
	!obj:pylearn2.train_extensions.roc_auc.RocAucChannel {
	    channel_name: 'roc_auc'
	}
    ],
#+END_SRC

*** DONE Research monitoring channel implementation
    CLOSED: [2015-02-19 Thu 22:22]
    :LOGBOOK:  
    - State "DONE"       from "NEXT"       [2015-02-19 Thu 22:22]
    CLOCK: [2015-02-19 Thu 20:40]--[2015-02-19 Thu 22:22] =>  1:42
    - State "NEXT"       from ""           [2015-02-19 Thu 20:10]
    :END:      
    - cool find, C-c C-x C-j goes to currently clocked in task
      
Here let's take a look at the multiclass log loss function.

#+NAME: multiclass_log_loss
#+begin_src python :noeval
def multiclass_log_loss(y_true, y_pred, eps=1e-15):
    predictions = np.clip(y_pred, eps, 1 - eps)

    # normalize row sums to 1
    predictions /= predictions.sum(axis=1)[:, np.newaxis]

    actual = np.zeros(y_pred.shape)
    n_samples = actual.shape[0]
    actual[np.arange(n_samples), y_true.astype(int)] = 1
    vectsum = np.sum(actual * np.log(predictions))
    loss = -1.0 / n_samples * vectsum
    return loss
#+end_src

That's straight forward enough. As for adding a monitoring
extension to pylearn, am referring to the roc_auc. It is
using y and y_hat. Exactly what are these and what format do
they take so I can appropriately feed them to the MLL?

I put a ~pdb.set_trace~ in the roc_auc monitor to find out.

#+begin_src python :noeval
y = T.argmax(target, axis=1)
y_hat = model.fprop(state)[:, self.positive_class_index]
#+end_src

#+begin_src python :noeval
(Pdb) p type(y)
<class 'theano.tensor.var.TensorVariable'>
(Pdb) p type(y_hat)
<class 'theano.tensor.var.TensorVariable'>
#+end_src

So these are simply symbols. 

Moving forward a few lines we come across

#+begin_src python :noeval
#...
    pos = T.eq(y, self.positive_class_index)
    neg = T.eq(y, self.negative_class_index)
    keep = T.add(pos, neg).nonzero()
    y = T.eq(y[keep], self.positive_class_index)
    y_hat = y_hat[keep]

roc_auc = RocAucScoreOp(self.channel_name_suffix)(y, y_hat)
roc_auc = T.cast(roc_auc, config.floatX)
#+end_src

Take note that for roc_auc, posotive and negative cases were
identified.

~RocAucScoreOp~ is a theano operation wrapper to sklearn's
roc_auc metric. In other words we need to get our metric to
work using theano's symbolic expressions.

That doesn't do any calculcations yet, just further sets up
the theano components. ~cast~ in the next line simply
changes its type to a flot.

Finally, the tensor is passed to ~monitor.add_channel~

#+begin_src python :noeval
model.monitor.add_channel(name=channel_name,
                          ipt=(state, target),
                          val=roc_auc,
                          data_specs=(m_space, m_source),
                          dataset=dataset)
#+end_src

with ~theano.pp~ we can nicely print the symbolic
expressions. I didn't import that so can't do it right now.

Continuing with pdb

Our ~roc_auc~ is now a float operation, but it's not being
used yet.

Late hours approach and this is where I would retire. So
I'll make a leap to ~monitor.add_channel~ and see what's
going on. After all, that's as far as I need to get.

#+begin_src python :noeval
add_channel(self, name, ipt, val, dataset=None, prereqs=None,
            data_specs=None):
"""
Asks the monitor to start tracking a new value.  Can be called
even after the monitor is already in use.

Parameters
----------
name : str
    The display name in the monitor.
ipt : tensor_like
    The symbolic tensor which should be clamped to the data.
    (or a list/tuple containing symbolic tensors, following the
    data_specs)
val : tensor_like
    The value (function of `ipt`) to be tracked.
dataset : pylearn2.datasets.Dataset
    Which dataset to compute this channel on
prereqs : list of callables that take a list of numpy tensors
    Each prereq must be called exactly once per each new batch
    of data drawn *from dataset* before the channel value is
    computed if two channels provide a prereq with exactly the
    same id, that prereq will only be called once
data_specs : (space, source) pair
    Identifies the order, format and semantics of ipt
"""

#+end_src

I only need to get the proper tensor expressions set up for
ipt and val. And from the looks of things, I only need to
adjust the theano wrapper of roc_auc to return an expression
for MLL.

It would be good to see another example. But I can't find.
Hold on now - here's the one for the misclassification rate.

#+begin_src python :noeval
if (targets is not None):
    if ((not self._has_binary_target) or
            self.binary_target_dim == 1):
        # if binary_target_dim>1, the misclass rate is ill-defined
        y_hat = T.argmax(state, axis=1)
        y = (targets.reshape(y_hat.shape)
             if self._has_binary_target
             else T.argmax(targets, axis=1))
        misclass = T.neq(y, y_hat).mean()
        misclass = T.cast(misclass, config.floatX)
        rval['misclass'] = misclass
    rval['nll'] = self.cost(Y_hat=state, Y=targets)
#+end_src

I think that exemplifies how straight forward this can be.
The proportion of nonmatching elements of the observed y and
predicted y_hat from the total number of observations is the
misclassifcation rate.

For me, y_hat must be probabilities, not classes. Om that
case it is easy, remove the argmax line, which decides
assigns a class based on the maximum probability.

In other words, replace the 

#+begin_src python :noeval
misclass = T.neq(y, y_hat).mean()
#+end_src

with a tensor expression for multiclass log loss.
[[multiclass_log_loss]]
*** DONE Implement theano multiclass log loss
    CLOSED: [2015-02-21 Sat 22:51]
    :LOGBOOK:  
    - State "DONE"       from "NEXT"       [2015-02-21 Sat 22:51]
    CLOCK: [2015-02-21 Sat 13:11]
    - State "NEXT"       from "TODO"       [2015-02-19 Thu 22:23]
    :END:      
So let's break down the MLL. I went through it line by line
in [[file:multiclass_log_loss_test.ipynb]]

#+begin_src python :noeval
def multiclass_log_loss(y_true, y_pred, eps=1e-15):
    # clip values to >0 and <1 - needed?
    predictions = np.clip(y_pred, eps, 1 - eps)

    # normalize row sums to 1
    predictions /= predictions.sum(axis=1)[:, np.newaxis]

    # array, same shape as predictions, with 'true' predictions
    actual = np.zeros(y_pred.shape)
    n_samples = actual.shape[0]
    actual[np.arange(n_samples), y_true.astype(int)] = 1

    # elementwise product of log(predictions) and true classes
    vectsum = np.sum(actual * np.log(predictions))

    loss = -1.0 / n_samples * vectsum
    return loss
#+end_src

See the [[http://deeplearning.net/software/theano/tutorial/index.html#tutorial][theano tutorial]] for a start.

My last question - where is a function made from the tensor
and evaluated?

Also, be careful of the shape of y, it may be a column/row.

Be aware of broadcasting, and the [[http://deeplearning.net/software/theano/library/tensor/basic.html][default tensor
functionality]], which should be enough for my purposes.

#+begin_src python :noeval
def multiclass_log_loss(y_true, y_pred):
    """Multi class version of Logarithmic Loss metric.
    https://www.kaggle.com/wiki/MultiClassLogLoss

    Parameters
    ----------
    y_true : array, shape = [n_samples]
            true class, intergers in [0, n_classes - 1)
    y_pred : array, shape = [n_samples, n_classes]

    Returns
    -------
    loss : float
    """
    y_pred = T.matrix(dtype='float32')
    y_true = T.matrix('y_true', dtype='int32')
    y_true_square = T.matrix('y_true_square', dtype='int32')
    eps = T.constant(1e-15, 'eps', dtype='float32')

    n_samples = y_pred.shape[0]
    y_pred_clip = T.clip(y_pred, eps, 1-eps)
    y_pred_row_sum = y_pred_clip.sum(axis=1)[:, np.newaxis]
    y_pred_norm = y_pred_clip / y_pred_row_sum
    y_true_square_ones = T.set_subtensor(y_true_square[T.arange(y_true.shape[0]), y_true.dimshuffle(1,0)], 1)
    y_pred_log = T.log(y_pred_norm)
    log_true_prod = y_true_square_ones * y_pred_log
    loss = -1.0 / n_samples * log_true_prod.sum()

    log_loss = function([y_pred, y_true, y_true_square], loss)
#+end_src

Where will we pass epsilon? We can put constants in our
theano expressions

#+begin_src python :noeval
from theano import tensor as T, function
x = T.dmatrix('x')
s = 1 / (1 + T.exp(-x))
logistic = function([x], s)
logistic([[0, 1], [-1, -2]])
#+end_src

Well, I did implement MLL in theano expressions. But it
turns out it was unnecessary. As the calculation need not be
in theano expressions, as the values are passed through
theano to the actual score function. Take a look

#+begin_src sh :results table code replace output 
fileOne="./pylearn2_fork/pylearn2/train_extensions/multiclass_log_loss.py"
fileTwo="./pylearn2_fork/pylearn2/train_extensions/roc_auc.py"
diff -y $fileOne $fileTwo
#+end_src

#+RESULTS:
#+BEGIN_SRC sh
"""								"""
TrainExtension subclass for calculating multiclass log loss o |	TrainExtension subclass for calculating ROC AUC scores on mon
dataset(s), reported via monitor channels.			dataset(s), reported via monitor channels.
"""								"""

__author__ = "Jotham Apaloo"				      |	__author__ = "Steven Kearnes"
__copyright__ = "Copyright 2015"			      |	__copyright__ = "Copyright 2014, Stanford University"
__license__ = "TBD"					      |	__license__ = "3-clause BSD"
__maintainer__ = "Jotham Apaloo"			      |	__maintainer__ = "Steven Kearnes"

import numpy as np						import numpy as np
							      >	try:
							      >	    from sklearn.metrics import roc_auc_score
							      >	except ImportError:
							      >	    roc_auc_score = None
							      >
import theano							import theano
import pdb						      <
from theano import gof, config					from theano import gof, config
from theano import tensor as T					from theano import tensor as T

from pylearn2.train_extensions import TrainExtension		from pylearn2.train_extensions import TrainExtension

def multiclass_log_loss(y_true, y_pred, eps=1e-15):	      <
    """Multi class version of Logarithmic Loss metric.	      <
    https://www.kaggle.com/wiki/MultiClassLogLoss	      <
							      <
    Parameters						      <
    ----------						      <
    y_true : array, shape = [n_samples, n_classes]	      <
            true class, column index with unit value = true   <
            class for sample				      <
    y_pred : array, shape = [n_samples, n_classes]	      <
							      <
    Returns						      <
    -------						      <
    loss : float					      <
    """							      <
    pdb.set_trace()					      <
    predictions = np.clip(y_pred, eps, 1 - eps)		      <
							      <
    # normalize row sums to 1				      <
    predictions /= predictions.sum(axis=1)[:, np.newaxis]     <
							      <
    actual = y_true					      <
    n_samples = actual.shape[0]				      <
    #actual[np.arange(n_samples), y_true.astype(int)] = 1     <
    vectsum = np.sum(y_true * np.log(predictions))	      <
    loss = -1.0 / n_samples * vectsum			      <
    return loss						      <
							      <

class MulticlassLogLossOp(gof.Op):			      |	class RocAucScoreOp(gof.Op):
    """								    """
    Brief description.					      |	    Theano Op wrapping sklearn.metrics.roc_auc_score.

    Parameters							    Parameters
    ----------							    ----------
    name : str, optional (default 'mll')		      |	    name : str, optional (default 'roc_auc')
        Name of this Op.					        Name of this Op.
    use_c_code : WRITEME					    use_c_code : WRITEME
    """								    """
    def __init__(self, name='mll', use_c_code=theano.config.c |	    def __init__(self, name='roc_auc', use_c_code=theano.conf
        super(MulticlassLogLossOp, self).__init__(use_c_code) |	        super(RocAucScoreOp, self).__init__(use_c_code)
        self.name = name					        self.name = name

    def make_node(self, y_true, y_score):			    def make_node(self, y_true, y_score):
        """							        """
        Calculate mll.					      |	        Calculate ROC AUC score.

        Parameters						        Parameters
        ----------						        ----------
        y_true : tensor_like					        y_true : tensor_like
            Target class labels.				            Target class labels.
        y_score : tensor_like					        y_score : tensor_like
            Predicted probabilities for all classes class.    |	            Predicted class labels or probabilities for posit
        """							        """
        y_true = T.as_tensor_variable(y_true)			        y_true = T.as_tensor_variable(y_true)
        y_score = T.as_tensor_variable(y_score)			        y_score = T.as_tensor_variable(y_score)
        output = [T.scalar(name=self.name, dtype=config.float	        output = [T.scalar(name=self.name, dtype=config.float
        return gof.Apply(self, [y_true, y_score], output)	        return gof.Apply(self, [y_true, y_score], output)

    def perform(self, node, inputs, output_storage):		    def perform(self, node, inputs, output_storage):
        """							        """
        Calculate mll.					      |	        Calculate ROC AUC score.

        Parameters						        Parameters
        ----------						        ----------
        node : Apply instance					        node : Apply instance
            Symbolic inputs and outputs.			            Symbolic inputs and outputs.
        inputs : list						        inputs : list
            Sequence of inputs.					            Sequence of inputs.
        output_storage : list					        output_storage : list
            List of mutable 1-element lists.			            List of mutable 1-element lists.
        """							        """
							      >	        if roc_auc_score is None:
							      >	            raise RuntimeError("Could not import from sklearn
        y_true, y_score = inputs				        y_true, y_score = inputs
        try:							        try:
            mll = multiclass_log_loss(y_true, y_score)	      |	            roc_auc = roc_auc_score(y_true, y_score)
        except ValueError:					        except ValueError:
            mll = np.nan				      |	            roc_auc = np.nan
        output_storage[0][0] = theano._asarray(mll, dtype=con |	        output_storage[0][0] = theano._asarray(roc_auc, dtype


class MLLChannel(TrainExtension):			      |	class RocAucChannel(TrainExtension):
    """								    """
    Adds a mll channel to the monitor for each monitoring dat |	    Adds a ROC AUC channel to the monitor for each monitoring

    This monitor MAY return nan unless all classes are repres |	    This monitor will return nan unless both classes are repr
    y_true. For this reason, it is recommended to set monitor	    y_true. For this reason, it is recommended to set monitor
    to 1, especially when using unbalanced datasets.		    to 1, especially when using unbalanced datasets.

    Parameters							    Parameters
    ----------							    ----------
    channel_name_suffix : str, optional (default 'mll')	      |	    channel_name_suffix : str, optional (default 'roc_auc')
        Channel name suffix.					        Channel name suffix.
    positive_class_index : int, optional (default 1)		    positive_class_index : int, optional (default 1)
        Index of positive class in predicted values.		        Index of positive class in predicted values.
    negative_class_index : int or None, optional (default Non	    negative_class_index : int or None, optional (default Non
        Index of negative class in predicted values for calcu	        Index of negative class in predicted values for calcu
        one vs. one performance. If None, uses all examples n	        one vs. one performance. If None, uses all examples n
        positive class (one vs. the rest).			        positive class (one vs. the rest).
    """								    """
    def __init__(self, channel_name_suffix='mll', positive_cl |	    def __init__(self, channel_name_suffix='roc_auc', positiv
                 negative_class_index=None):			                 negative_class_index=None):
        self.channel_name_suffix = channel_name_suffix		        self.channel_name_suffix = channel_name_suffix
        self.positive_class_index = positive_class_index	        self.positive_class_index = positive_class_index
        self.negative_class_index = negative_class_index	        self.negative_class_index = negative_class_index

    def setup(self, model, dataset, algorithm):			    def setup(self, model, dataset, algorithm):
        """							        """
        Add mll channels for monitoring dataset(s) to model.m |	        Add ROC AUC channels for monitoring dataset(s) to mod

        Parameters						        Parameters
        ----------						        ----------
        model : object						        model : object
            The model being trained.				            The model being trained.
        dataset : object					        dataset : object
            Training dataset.					            Training dataset.
        algorithm : object					        algorithm : object
            Training algorithm.					            Training algorithm.
        """							        """
        m_space, m_source = model.get_monitoring_data_specs()	        m_space, m_source = model.get_monitoring_data_specs()
        state, target = m_space.make_theano_batch()		        state, target = m_space.make_theano_batch()

        y = target					      |	        y = T.argmax(target, axis=1)
        y_hat = model.fprop(state)			      |	        y_hat = model.fprop(state)[:, self.positive_class_ind

        mll = MulticlassLogLossOp(self.channel_name_suffix)(y |	        # one vs. the rest
        mll = T.cast(mll, config.floatX)		      |	        if self.negative_class_index is None:
							      >	            y = T.eq(y, self.positive_class_index)
							      >
							      >	        # one vs. one
							      >	        else:
							      >	            pos = T.eq(y, self.positive_class_index)
							      >	            neg = T.eq(y, self.negative_class_index)
							      >	            keep = T.add(pos, neg).nonzero()
							      >	            y = T.eq(y[keep], self.positive_class_index)
							      >	            y_hat = y_hat[keep]

							      >	        roc_auc = RocAucScoreOp(self.channel_name_suffix)(y, 
							      >	        roc_auc = T.cast(roc_auc, config.floatX)
        for dataset_name, dataset in algorithm.monitoring_dat	        for dataset_name, dataset in algorithm.monitoring_dat
            if dataset_name:					            if dataset_name:
                channel_name = '{0}_{1}'.format(dataset_name,	                channel_name = '{0}_{1}'.format(dataset_name,
                                                self.channel_	                                                self.channel_
            else:						            else:
                channel_name = self.channel_name_suffix		                channel_name = self.channel_name_suffix
            model.monitor.add_channel(name=channel_name,	            model.monitor.add_channel(name=channel_name,
                                      ipt=(state, target),	                                      ipt=(state, target),
                                      val=mll,		      |	                                      val=roc_auc,
                                      data_specs=(m_space, m_	                                      data_specs=(m_space, m_
                                      dataset=dataset)		                                      dataset=dataset)
"""								"""
TrainExtension subclass for calculating multiclass log loss o |	TrainExtension subclass for calculating ROC AUC scores on mon
dataset(s), reported via monitor channels.			dataset(s), reported via monitor channels.
"""								"""

__author__ = "Jotham Apaloo"				      |	__author__ = "Steven Kearnes"
__copyright__ = "Copyright 2015"			      |	__copyright__ = "Copyright 2014, Stanford University"
__license__ = "TBD"					      |	__license__ = "3-clause BSD"
__maintainer__ = "Jotham Apaloo"			      |	__maintainer__ = "Steven Kearnes"

import numpy as np						import numpy as np
							      >	try:
							      >	    from sklearn.metrics import roc_auc_score
							      >	except ImportError:
							      >	    roc_auc_score = None
							      >
import theano							import theano
import pdb						      <
from theano import gof, config					from theano import gof, config
from theano import tensor as T					from theano import tensor as T

from pylearn2.train_extensions import TrainExtension		from pylearn2.train_extensions import TrainExtension

def multiclass_log_loss(y_true, y_pred, eps=1e-15):	      <
    """Multi class version of Logarithmic Loss metric.	      <
    https://www.kaggle.com/wiki/MultiClassLogLoss	      <
							      <
    Parameters						      <
    ----------						      <
    y_true : array, shape = [n_samples, n_classes]	      <
            true class, column index with unit value = true   <
            class for sample				      <
    y_pred : array, shape = [n_samples, n_classes]	      <
							      <
    Returns						      <
    -------						      <
    loss : float					      <
    """							      <
    pdb.set_trace()					      <
    predictions = np.clip(y_pred, eps, 1 - eps)		      <
							      <
    # normalize row sums to 1				      <
    predictions /= predictions.sum(axis=1)[:, np.newaxis]     <
							      <
    actual = y_true					      <
    n_samples = actual.shape[0]				      <
    #actual[np.arange(n_samples), y_true.astype(int)] = 1     <
    vectsum = np.sum(y_true * np.log(predictions))	      <
    loss = -1.0 / n_samples * vectsum			      <
    return loss						      <
							      <

class MulticlassLogLossOp(gof.Op):			      |	class RocAucScoreOp(gof.Op):
    """								    """
    Brief description.					      |	    Theano Op wrapping sklearn.metrics.roc_auc_score.

    Parameters							    Parameters
    ----------							    ----------
    name : str, optional (default 'mll')		      |	    name : str, optional (default 'roc_auc')
        Name of this Op.					        Name of this Op.
    use_c_code : WRITEME					    use_c_code : WRITEME
    """								    """
    def __init__(self, name='mll', use_c_code=theano.config.c |	    def __init__(self, name='roc_auc', use_c_code=theano.conf
        super(MulticlassLogLossOp, self).__init__(use_c_code) |	        super(RocAucScoreOp, self).__init__(use_c_code)
        self.name = name					        self.name = name

    def make_node(self, y_true, y_score):			    def make_node(self, y_true, y_score):
        """							        """
        Calculate mll.					      |	        Calculate ROC AUC score.

        Parameters						        Parameters
        ----------						        ----------
        y_true : tensor_like					        y_true : tensor_like
            Target class labels.				            Target class labels.
        y_score : tensor_like					        y_score : tensor_like
            Predicted probabilities for all classes class.    |	            Predicted class labels or probabilities for posit
        """							        """
        y_true = T.as_tensor_variable(y_true)			        y_true = T.as_tensor_variable(y_true)
        y_score = T.as_tensor_variable(y_score)			        y_score = T.as_tensor_variable(y_score)
        output = [T.scalar(name=self.name, dtype=config.float	        output = [T.scalar(name=self.name, dtype=config.float
        return gof.Apply(self, [y_true, y_score], output)	        return gof.Apply(self, [y_true, y_score], output)

    def perform(self, node, inputs, output_storage):		    def perform(self, node, inputs, output_storage):
        """							        """
        Calculate mll.					      |	        Calculate ROC AUC score.

        Parameters						        Parameters
        ----------						        ----------
        node : Apply instance					        node : Apply instance
            Symbolic inputs and outputs.			            Symbolic inputs and outputs.
        inputs : list						        inputs : list
            Sequence of inputs.					            Sequence of inputs.
        output_storage : list					        output_storage : list
            List of mutable 1-element lists.			            List of mutable 1-element lists.
        """							        """
							      >	        if roc_auc_score is None:
							      >	            raise RuntimeError("Could not import from sklearn
        y_true, y_score = inputs				        y_true, y_score = inputs
        try:							        try:
            mll = multiclass_log_loss(y_true, y_score)	      |	            roc_auc = roc_auc_score(y_true, y_score)
        except ValueError:					        except ValueError:
            mll = np.nan				      |	            roc_auc = np.nan
        output_storage[0][0] = theano._asarray(mll, dtype=con |	        output_storage[0][0] = theano._asarray(roc_auc, dtype


class MLLChannel(TrainExtension):			      |	class RocAucChannel(TrainExtension):
    """								    """
    Adds a mll channel to the monitor for each monitoring dat |	    Adds a ROC AUC channel to the monitor for each monitoring

    This monitor MAY return nan unless all classes are repres |	    This monitor will return nan unless both classes are repr
    y_true. For this reason, it is recommended to set monitor	    y_true. For this reason, it is recommended to set monitor
    to 1, especially when using unbalanced datasets.		    to 1, especially when using unbalanced datasets.

    Parameters							    Parameters
    ----------							    ----------
    channel_name_suffix : str, optional (default 'mll')	      |	    channel_name_suffix : str, optional (default 'roc_auc')
        Channel name suffix.					        Channel name suffix.
    positive_class_index : int, optional (default 1)		    positive_class_index : int, optional (default 1)
        Index of positive class in predicted values.		        Index of positive class in predicted values.
    negative_class_index : int or None, optional (default Non	    negative_class_index : int or None, optional (default Non
        Index of negative class in predicted values for calcu	        Index of negative class in predicted values for calcu
        one vs. one performance. If None, uses all examples n	        one vs. one performance. If None, uses all examples n
        positive class (one vs. the rest).			        positive class (one vs. the rest).
    """								    """
    def __init__(self, channel_name_suffix='mll', positive_cl |	    def __init__(self, channel_name_suffix='roc_auc', positiv
                 negative_class_index=None):			                 negative_class_index=None):
        self.channel_name_suffix = channel_name_suffix		        self.channel_name_suffix = channel_name_suffix
        self.positive_class_index = positive_class_index	        self.positive_class_index = positive_class_index
        self.negative_class_index = negative_class_index	        self.negative_class_index = negative_class_index

    def setup(self, model, dataset, algorithm):			    def setup(self, model, dataset, algorithm):
        """							        """
        Add mll channels for monitoring dataset(s) to model.m |	        Add ROC AUC channels for monitoring dataset(s) to mod

        Parameters						        Parameters
        ----------						        ----------
        model : object						        model : object
            The model being trained.				            The model being trained.
        dataset : object					        dataset : object
            Training dataset.					            Training dataset.
        algorithm : object					        algorithm : object
            Training algorithm.					            Training algorithm.
        """							        """
        m_space, m_source = model.get_monitoring_data_specs()	        m_space, m_source = model.get_monitoring_data_specs()
        state, target = m_space.make_theano_batch()		        state, target = m_space.make_theano_batch()

        y = target					      |	        y = T.argmax(target, axis=1)
        y_hat = model.fprop(state)			      |	        y_hat = model.fprop(state)[:, self.positive_class_ind

        mll = MulticlassLogLossOp(self.channel_name_suffix)(y |	        # one vs. the rest
        mll = T.cast(mll, config.floatX)		      |	        if self.negative_class_index is None:
							      >	            y = T.eq(y, self.positive_class_index)
							      >
							      >	        # one vs. one
							      >	        else:
							      >	            pos = T.eq(y, self.positive_class_index)
							      >	            neg = T.eq(y, self.negative_class_index)
							      >	            keep = T.add(pos, neg).nonzero()
							      >	            y = T.eq(y[keep], self.positive_class_index)
							      >	            y_hat = y_hat[keep]

							      >	        roc_auc = RocAucScoreOp(self.channel_name_suffix)(y, 
							      >	        roc_auc = T.cast(roc_auc, config.floatX)
        for dataset_name, dataset in algorithm.monitoring_dat	        for dataset_name, dataset in algorithm.monitoring_dat
            if dataset_name:					            if dataset_name:
                channel_name = '{0}_{1}'.format(dataset_name,	                channel_name = '{0}_{1}'.format(dataset_name,
                                                self.channel_	                                                self.channel_
            else:						            else:
                channel_name = self.channel_name_suffix		                channel_name = self.channel_name_suffix
            model.monitor.add_channel(name=channel_name,	            model.monitor.add_channel(name=channel_name,
                                      ipt=(state, target),	                                      ipt=(state, target),
                                      val=mll,		      |	                                      val=roc_auc,
                                      data_specs=(m_space, m_	                                      data_specs=(m_space, m_
                                      dataset=dataset)		                                      dataset=dataset)
#+END_SRC

It wasn't too much to get this working. It was a lot to
stomach the fact that my MLL matched the objective
function - the negative log likelihood.

They are indeed one and the same. It even said so in the
[[https://www.kaggle.com/wiki/MultiClassLogLoss][Kaggle]]

#+begin_src 
The metric is negative the log likelihood of the model
#+end_src

Oh well. I learned a great deal about Theano, at least.

*** Issues
One of the problems here is GPU processing is only working
with 32 bit values.

** DONE Note
   CLOSED: [2015-02-21 Sat 22:53]
   :LOGBOOK:  
   - State "DONE"       from ""           [2015-02-21 Sat 22:53]
   :END:      
   - some NLL and MLL are same thing
   - but my NLL score on data is much better than my
     submission
   - indicates overfitting
   - image augmentation will help, along with the CNN
** DONE Make the workflow better
   CLOSED: [2015-02-22 Sun 00:35]
   :LOGBOOK:  
   - State "DONE"       from "NEXT"       [2015-02-22 Sun 00:35]
   - State "NEXT"       from ""           [2015-02-17 Tue 22:47]
   :END:      
Expiriments are defined with yaml.
I run the yaml in an ipython notebook.

The best and last model are saved.
Load up the best model and run the predictions.

Can I move these notebooks to a new directory?
Where are paths ill coded? 
Data path is hard coded, doesn't matter relative to ipynb paths.

** DONE Get running on GPU/desktop [3/3]
   CLOSED: [2015-02-23 Mon 21:20]
   :LOGBOOK:  
   - State "DONE"       from "NEXT"       [2015-02-23 Mon 21:20]
   - State "NEXT"       from "TODO"       [2015-02-22 Sun 00:36]
   :END:      
   - create venv
   - update requirements.txt, remove pylearn fork, ssh it over
   - install reqs
   - clone project repo
   - ssh data over
   - ssh theano config over, add gpu

*** DONE Move existing work over
    CLOSED: [2015-02-22 Sun 17:34]
    :LOGBOOK:  
    - State "DONE"       from ""           [2015-02-22 Sun 17:34]
    :END:      
#+begin_src sh :noeval
mkproject -p /usr/bin/python2.7 2014-12-20_datascibowl
#+end_src

#+begin_src sh :noeval
pip freeze > requirements.txt
# delete fork of pylearn, we'll clone it later
scp requirements.txt jotham@192.168.0.13:/home/jotham/projects/2014-12-20_datascibowl/requirements.txt
#+end_src

#+begin_src sh :noeval
pip install numpy # have to install this for scikit-image
pip install six # have to install this for scikit-image
pip install numexp # have to install this for scikit-image
pip install Cython # have to install this for scikit-image
sudo pacman -S hdf5 # for pyhdf
pip install -r requirements.txt
git clone git:@gitlab.com:Jotham/20141220_datascibowl.git
#+end_src

#+begin_src sh :noeval
scp -r data jotham@192.168.0.13:/home/jotham/projects/2014-12-20_datascibowl/
scp -r competition_data jotham@192.168.0.13:/home/jotham/projects/2014-12-20_datascibowl/
scp ~/.theanorc jotham@192.168.0.13:/home/jotham/.theanorc
#+end_src

#+begin_src sh :noeval
git clone git@github.com:jo-tham/pylearn2.git pylearn2_fork
cd pylearn2_fork 
python setyp.py develop
#+end_src
*** DONE Setup theano with CUDA for gpu computing
    CLOSED: [2015-02-22 Sun 21:06]
    :LOGBOOK:  
    - State "DONE"       from "NEXT"       [2015-02-22 Sun 21:06]
    - State "NEXT"       from "WAITING"    [2015-02-22 Sun 21:06]
    - State "WAITING"    from ""           [2015-02-22 Sun 19:58] \\
      - waiting for new kernel/nvidia drivers
      - until then, cpu only
    :END:      
The guide is [[http://deeplearning.net/software/theano/install.html#gpu-linux][here]]. Rough steps are as follows.

CUDA, nvidia's proprietary gear for general purpose
computing on GPUs, ships with nvidia.

#+begin_src sh :results verbatim code replace output 
pacman -Qs nvidia
#+end_src
#+RESULTS:
#+BEGIN_SRC sh
local/libcl 1.1-4
    OpenCL library and ICD loader from NVIDIA
local/libvdpau 0.9-1
    Nvidia VDPAU library
local/nvidia 346.35-6
    NVIDIA drivers for linux
local/nvidia-libgl 346.35-2
    NVIDIA drivers libraries symlinks
local/nvidia-utils 346.35-2
    NVIDIA drivers utilities
#+END_SRC

We also need the cuda toolkit

#+begin_src sh :noeval
sudo pacman -S cuda
#+end_src

Cuda installs all components in the directory ~/opt/cuda~.
To compile CUDA code, add ~/opt/cuda/include~ to the
include path in the compiler instructions. 
Knowing this we can update ~.theanorc~.

#+begin_src sh :results verbatim code replace output 
cat ~/.theanorc
#+end_src
#+RESULTS:
#+BEGIN_SRC sh
[global]
exception_verbosity = high
optimizer = fast_compile
device = gpu0
floatX = float32

[cuda]
root = /opt/cuda
#+END_SRC

I tried this test of the theano authors, but it failed
#+begin_src python :noeval
from theano import function, config, shared, sandbox
import theano.tensor as T
import numpy
import time

vlen = 10 * 30 * 768  # 10 x #cores x # threads per core
iters = 1000

rng = numpy.random.RandomState(22)
x = shared(numpy.asarray(rng.rand(vlen), config.floatX))
f = function([], T.exp(x))
print f.maker.fgraph.toposort()
t0 = time.time()
for i in xrange(iters):
    r = f()
t1 = time.time()
print 'Looping %d times took' % iters, t1 - t0, 'seconds'
print 'Result is', r
if numpy.any([isinstance(x.op, T.Elemwise) for x in f.maker.fgraph.toposort()]):
    print 'Used the cpu'
else:
    print 'Used the gpu'
#+end_src

#+begin_src sh :results verbatim code replace output
python theano_gpu_test.py
# WARNING (theano.sandbox.cuda): CUDA is installed, but
# device gpu is not available (error: Unable to get the
# number of gpus available: unknown error)
#+end_src

#+begin_src sh :results verbatim code replace output
nvidia-smi
#+end_src

#+RESULTS:
#+BEGIN_SRC sh
Sun Feb 22 18:06:24 2015       
+------------------------------------------------------+                       
| NVIDIA-SMI 346.35     Driver Version: 346.35         |                       
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  GeForce GTX 550 Ti  Off  | 0000:01:00.0     N/A |                  N/A |
| 15%   38C    P8    N/A /  N/A |    131MiB /  1023MiB |     N/A      Default |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID  Type  Process name                               Usage      |
|=============================================================================|
|    0              C   Not Supported                                         |
+-----------------------------------------------------------------------------+
#+END_SRC

A similar problem is reported on the [[https://groups.google.com/forum/#!msg/theano-users/xW9jmHzOwp0/8SvMA_R0EAUJ][google groups]]. 

I tried running ~nvidia-smi~ as sudo to [[modules][initialize the
device files]]. Things still didn't work.

Well, it turns out the nvidia driver 346.35 may have some
[[https://www.google.ca/search?q=nvidia+driver+346.35+linu+kernel+3.18.2&ie=utf-8&oe=utf-8&gws_rd=cr&ei=pnnqVJejGYiyyAT9hoCADw][issues with current kernel]]

CURSES!

With a reboot, it pretends to be working, but appears to use
the CPU anyway. WTH?@!

#+begin_src 
Using gpu device 0: GeForce GTX 550 Ti
[HostFromGpu(<CudaNdarrayType(float32, vector)>), Elemwise{exp,no_inplace}(HostFromGpu.0)]
Looping 1000 times took 5.19549107552 seconds
Result is [ 1.23178029  1.61879337  1.52278066 ...,  2.20771813  2.29967761
  1.62323284]
Used the cpu
#+end_src

So I try running theano's test suite in
[[file:ipynb_tests/theano_gpu.ipynb]]

Those tests [[http://comments.gmane.org/gmane.comp.mathematics.theano.user/3521][should be run with cpu]].

also, 

#+begin_src sh :noeval
pip install pycuda
#+end_src

Im at my ends. Why didn't the wee test with GPU work?

Enough, I just try the softmax_03 with gpu. The cpu load is 100%...

This is not working...
*** DONE Troubleshoot theano on gpu
    CLOSED: [2015-02-23 Mon 21:20]
    :LOGBOOK:  
    - State "DONE"       from "NEXT"       [2015-02-23 Mon 21:20]
    - State "NEXT"       from ""           [2015-02-22 Sun 21:06]
    :END:      

OK, I tried tons of stuff. In the end, with [[https://groups.google.com/forum/#!searchin/theano-users/gpu/theano-users/IJL7DIwKutQ/NLCKl_ORzCsJ ][this]] suggestion
and forcing the device, things worked. Suspicious as to
whether pylearn really using GPU. How to know?



Friggin laptop was faster, 400 instead of 600 seconds per
epoch (although this may be due to it reverting to cpu when
gpu computation doesn't work). Neeeeed GPU to work.

#+begin_src sh :noeval
export PATH=/opt/cuda/bin:$PATH
export LD_LIBRARY_PATH=/opt/cuda/lib64:$LD_LIBRARY_PATH
cd /opt/cuda/bin
install-samples.sh /opt/cuda/samples2
cd /opt/cuda/samples2/...
make
#+end_src

Several warnings like this:

#+begin_src sh :noeval
[@] mkdir -p ../../bin/x86_64/linux/release
[@] cp bilateralFilter ../../bin/x86_64/linux/release
make[1]: Leaving directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/3_Imaging/bilateralFilter'
make[1]: Entering directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/3_Imaging/imageDenoising'
>>> WARNING - libGL.so not found, refer to CUDA Samples release notes for how to find and install them. <<<
>>> WARNING - libGLU.so not found, refer to CUDA Samples release notes for how to find and install them. <<<
>>> WARNING - libX11.so not found, refer to CUDA Samples release notes for how to find and install them. <<<
>>> WARNING - libXi.so not found, refer to CUDA Samples release notes for how to find and install them. <<<
>>> WARNING - libXmu.so not found, refer to CUDA Samples release notes for how to find and install them. <<<
>>> WARNING - glu.h not found, refer to CUDA Samples release notes for how to find and install them. <<<
[@] /opt/cuda/bin/nvcc -ccbin g++ -I../../common/inc -m64 -gencode arch=compute_11,code=sm_11 -gencode arch=compute_20,code=sm_20 -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_37,code=sm_37 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_52,code=sm_52 -gencode arch=compute_52,code=compute_52 -o bmploader.o -c bmploader.cpp
[@] /opt/cuda/bin/nvcc -ccbin g++ -I../../common/inc -m64 -gencode arch=compute_11,code=sm_11 -gencode arch=compute_20,code=sm_20 -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_37,code=sm_37 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_52,code=sm_52 -gencode arch=compute_52,code=compute_52 -o imageDenoising.o -c imageDenoising.cu
[@] /opt/cuda/bin/nvcc -ccbin g++ -I../../common/inc -m64 -gencode arch=compute_11,code=sm_11 -gencode arch=compute_20,code=sm_20 -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_37,code=sm_37 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_52,code=sm_52 -gencode arch=compute_52,code=compute_52 -o imageDenoisingGL.o -c imageDenoisingGL.cpp
[@] /opt/cuda/bin/nvcc -ccbin g++ -m64 -gencode arch=compute_11,code=sm_11 -gencode arch=compute_20,code=sm_20 -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_37,code=sm_37 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_52,code=sm_52 -gencode arch=compute_52,code=compute_52 -o imageDenoising bmploader.o imageDenoising.o imageDenoisingGL.o -L../../common/lib/linux/x86_64 -lGL -lGLU -lX11 -lXi -lXmu -lglut -lGLEW
[@] mkdir -p ../../bin/x86_64/linux/release
[@] cp imageDenoising ../../bin/x86_64/linux/release
make[1]: Leaving directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/3_Imaging/imageDenoising'
make[1]: Entering directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/3_Imaging/histogram'
make[1]: Nothing to be done for 'all'.
make[1]: Leaving directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/3_Imaging/histogram'
make[1]: Entering directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/3_Imaging/cudaDecodeGL'
>>> WARNING - libGL.so not found, refer to CUDA Samples release notes for how to find and install them. <<<
>>> WARNING - libGLU.so not found, refer to CUDA Samples release notes for how to find and install them. <<<
>>> WARNING - libX11.so not found, refer to CUDA Samples release notes for how to find and install them. <<<
>>> WARNING - libXi.so not found, refer to CUDA Samples release notes for how to find and install them. <<<
>>> WARNING - libXmu.so not found, refer to CUDA Samples release notes for how to find and install them. <<<
>>> WARNING - glu.h not found, refer to CUDA Samples release notes for how to find and install them. <<<
[@] /opt/cuda/bin/nvcc -ccbin g++ -I../../common/inc -m64 -gencode arch=compute_11,code=compute_11 -o FrameQueue.o -c FrameQueue.cpp
[@] /opt/cuda/bin/nvcc -ccbin g++ -I../../common/inc -m64 -gencode arch=compute_11,code=compute_11 -o ImageGL.o -c ImageGL.cpp
[@] /opt/cuda/bin/nvcc -ccbin g++ -I../../common/inc -m64 -gencode arch=compute_11,code=compute_11 -o VideoDecoder.o -c VideoDecoder.cpp
[@] /opt/cuda/bin/nvcc -ccbin g++ -I../../common/inc -m64 -gencode arch=compute_11,code=compute_11 -o VideoParser.o -c VideoParser.cpp
[@] /opt/cuda/bin/nvcc -ccbin g++ -I../../common/inc -m64 -gencode arch=compute_11,code=compute_11 -o VideoSource.o -c VideoSource.cpp
[@] /opt/cuda/bin/nvcc -ccbin g++ -I../../common/inc -m64 -gencode arch=compute_11,code=compute_11 -o cudaModuleMgr.o -c cudaModuleMgr.cpp
[@] /opt/cuda/bin/nvcc -ccbin g++ -I../../common/inc -m64 -gencode arch=compute_11,code=compute_11 -o cudaProcessFrame.o -c cudaProcessFrame.cpp
[@] /opt/cuda/bin/nvcc -ccbin g++ -I../../common/inc -m64 -gencode arch=compute_11,code=compute_11 -o videoDecodeGL.o -c videoDecodeGL.cpp
[@] /opt/cuda/bin/nvcc -ccbin g++ -m64 -gencode arch=compute_11,code=compute_11 -o cudaDecodeGL FrameQueue.o ImageGL.o VideoDecoder.o VideoParser.o VideoSource.o cudaModuleMgr.o cudaProcessFrame.o videoDecodeGL.o -L../../common/lib/linux/x86_64 -lGL -lGLU -lX11 -lXi -lXmu -lglut -lGLEW -lcuda -lcudart -lnvcuvid
[@] mkdir -p ../../bin/x86_64/linux/release
[@] cp cudaDecodeGL ../../bin/x86_64/linux/release
[@] /opt/cuda/bin/nvcc -ccbin g++ -I../../common/inc -m64 -gencode arch=compute_11,code=compute_11 -o NV12ToARGB_drvapi64.ptx -ptx NV12ToARGB_drvapi.cu
[@] mkdir -p data
[@] cp -f NV12ToARGB_drvapi64.ptx ./data
[@] mkdir -p ../../bin/x86_64/linux/release
[@] cp -f NV12ToARGB_drvapi64.ptx ../../bin/x86_64/linux/release
make[1]: Leaving directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/3_Imaging/cudaDecodeGL'
make[1]: Entering directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/3_Imaging/dct8x8'
make[1]: Nothing to be done for 'all'.
make[1]: Leaving directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/3_Imaging/dct8x8'
make[1]: Entering directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/3_Imaging/SobelFilter'
>>> WARNING - libGL.so not found, refer to CUDA Samples release notes for how to find and install them. <<<
>>> WARNING - libGLU.so not found, refer to CUDA Samples release notes for how to find and install them. <<<
>>> WARNING - libX11.so not found, refer to CUDA Samples release notes for how to find and install them. <<<
>>> WARNING - libXi.so not found, refer to CUDA Samples release notes for how to find and install them. <<<
>>> WARNING - libXmu.so not found, refer to CUDA Samples release notes for how to find and install them. <<<
>>> WARNING - glu.h not found, refer to CUDA Samples release notes for how to find and install them. <<<
[@] /opt/cuda/bin/nvcc -ccbin g++ -I../../common/inc -m64 -gencode arch=compute_11,code=sm_11 -gencode arch=compute_20,code=sm_20 -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_37,code=sm_37 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_52,code=sm_52 -gencode arch=compute_52,code=compute_52 -o SobelFilter.o -c SobelFilter.cpp
[@] /opt/cuda/bin/nvcc -ccbin g++ -I../../common/inc -m64 -gencode arch=compute_11,code=sm_11 -gencode arch=compute_20,code=sm_20 -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_37,code=sm_37 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_52,code=sm_52 -gencode arch=compute_52,code=compute_52 -o SobelFilter_kernels.o -c SobelFilter_kernels.cu
[@] /opt/cuda/bin/nvcc -ccbin g++ -m64 -gencode arch=compute_11,code=sm_11 -gencode arch=compute_20,code=sm_20 -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_37,code=sm_37 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_52,code=sm_52 -gencode arch=compute_52,code=compute_52 -o SobelFilter SobelFilter.o SobelFilter_kernels.o -L../../common/lib/linux/x86_64 -lGL -lGLU -lX11 -lXi -lXmu -lglut -lGLEW
[@] mkdir -p ../../bin/x86_64/linux/release
[@] cp SobelFilter ../../bin/x86_64/linux/release
make[1]: Leaving directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/3_Imaging/SobelFilter'
make[1]: Entering directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/3_Imaging/stereoDisparity'
make[1]: Nothing to be done for 'all'.
make[1]: Leaving directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/3_Imaging/stereoDisparity'
make[1]: Entering directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/3_Imaging/convolutionTexture'
make[1]: Nothing to be done for 'all'.
make[1]: Leaving directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/3_Imaging/convolutionTexture'
make[1]: Entering directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/3_Imaging/dwtHaar1D'
make[1]: Nothing to be done for 'all'.
make[1]: Leaving directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/3_Imaging/dwtHaar1D'
make[1]: Entering directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/3_Imaging/recursiveGaussian'
>>> WARNING - libGL.so not found, refer to CUDA Samples release notes for how to find and install them. <<<
>>> WARNING - libGLU.so not found, refer to CUDA Samples release notes for how to find and install them. <<<
>>> WARNING - libX11.so not found, refer to CUDA Samples release notes for how to find and install them. <<<
>>> WARNING - libXi.so not found, refer to CUDA Samples release notes for how to find and install them. <<<
>>> WARNING - libXmu.so not found, refer to CUDA Samples release notes for how to find and install them. <<<
>>> WARNING - glu.h not found, refer to CUDA Samples release notes for how to find and install them. <<<
[@] /opt/cuda/bin/nvcc -ccbin g++ -I../../common/inc -m64 -gencode arch=compute_11,code=sm_11 -gencode arch=compute_20,code=sm_20 -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_37,code=sm_37 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_52,code=sm_52 -gencode arch=compute_52,code=compute_52 -o recursiveGaussian.o -c recursiveGaussian.cpp
[@] /opt/cuda/bin/nvcc -ccbin g++ -I../../common/inc -m64 -gencode arch=compute_11,code=sm_11 -gencode arch=compute_20,code=sm_20 -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_37,code=sm_37 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_52,code=sm_52 -gencode arch=compute_52,code=compute_52 -o recursiveGaussian_cuda.o -c recursiveGaussian_cuda.cu
[@] /opt/cuda/bin/nvcc -ccbin g++ -m64 -gencode arch=compute_11,code=sm_11 -gencode arch=compute_20,code=sm_20 -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_37,code=sm_37 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_52,code=sm_52 -gencode arch=compute_52,code=compute_52 -o recursiveGaussian recursiveGaussian.o recursiveGaussian_cuda.o -L../../common/lib/linux/x86_64 -lGL -lGLU -lX11 -lXi -lXmu -lglut -lGLEW
[@] mkdir -p ../../bin/x86_64/linux/release
[@] cp recursiveGaussian ../../bin/x86_64/linux/release
make[1]: Leaving directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/3_Imaging/recursiveGaussian'
make[1]: Entering directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/3_Imaging/convolutionFFT2D'
make[1]: Nothing to be done for 'all'.
make[1]: Leaving directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/3_Imaging/convolutionFFT2D'
make[1]: Entering directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/3_Imaging/HSOpticalFlow'
make[1]: Nothing to be done for 'all'.
make[1]: Leaving directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/3_Imaging/HSOpticalFlow'
make[1]: Entering directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/3_Imaging/boxFilter'
>>> WARNING - libGL.so not found, refer to CUDA Samples release notes for how to find and install them. <<<
>>> WARNING - libGLU.so not found, refer to CUDA Samples release notes for how to find and install them. <<<
>>> WARNING - libX11.so not found, refer to CUDA Samples release notes for how to find and install them. <<<
>>> WARNING - libXi.so not found, refer to CUDA Samples release notes for how to find and install them. <<<
>>> WARNING - libXmu.so not found, refer to CUDA Samples release notes for how to find and install them. <<<
>>> WARNING - glu.h not found, refer to CUDA Samples release notes for how to find and install them. <<<
[@] /opt/cuda/bin/nvcc -ccbin g++ -I../../common/inc -m64 -gencode arch=compute_11,code=sm_11 -gencode arch=compute_20,code=sm_20 -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_37,code=sm_37 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_52,code=sm_52 -gencode arch=compute_52,code=compute_52 -o boxFilter.o -c boxFilter.cpp
[@] /opt/cuda/bin/nvcc -ccbin g++ -I../../common/inc -m64 -gencode arch=compute_11,code=sm_11 -gencode arch=compute_20,code=sm_20 -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_37,code=sm_37 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_52,code=sm_52 -gencode arch=compute_52,code=compute_52 -o boxFilter_cpu.o -c boxFilter_cpu.cpp
[@] /opt/cuda/bin/nvcc -ccbin g++ -I../../common/inc -m64 -gencode arch=compute_11,code=sm_11 -gencode arch=compute_20,code=sm_20 -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_37,code=sm_37 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_52,code=sm_52 -gencode arch=compute_52,code=compute_52 -o boxFilter_kernel.o -c boxFilter_kernel.cu
[@] /opt/cuda/bin/nvcc -ccbin g++ -m64 -gencode arch=compute_11,code=sm_11 -gencode arch=compute_20,code=sm_20 -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_37,code=sm_37 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_52,code=sm_52 -gencode arch=compute_52,code=compute_52 -o boxFilter boxFilter.o boxFilter_cpu.o boxFilter_kernel.o -L../../common/lib/linux/x86_64 -lGL -lGLU -lX11 -lXi -lXmu -lglut -lGLEW
[@] mkdir -p ../../bin/x86_64/linux/release
[@] cp boxFilter ../../bin/x86_64/linux/release
make[1]: Leaving directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/3_Imaging/boxFilter'
make[1]: Entering directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/3_Imaging/convolutionSeparable'
make[1]: Nothing to be done for 'all'.
make[1]: Leaving directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/3_Imaging/convolutionSeparable'
make[1]: Entering directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/3_Imaging/dxtc'
make[1]: Nothing to be done for 'all'.
make[1]: Leaving directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/3_Imaging/dxtc'
make[1]: Entering directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/4_Finance/quasirandomGenerator'
make[1]: Nothing to be done for 'all'.
make[1]: Leaving directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/4_Finance/quasirandomGenerator'
make[1]: Entering directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/4_Finance/SobolQRNG'
make[1]: Nothing to be done for 'all'.
make[1]: Leaving directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/4_Finance/SobolQRNG'
make[1]: Entering directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/4_Finance/MonteCarloMultiGPU'
make[1]: Nothing to be done for 'all'.
make[1]: Leaving directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/4_Finance/MonteCarloMultiGPU'
make[1]: Entering directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/4_Finance/binomialOptions'
make[1]: Nothing to be done for 'all'.
make[1]: Leaving directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/4_Finance/binomialOptions'
make[1]: Entering directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/4_Finance/BlackScholes'
make[1]: Nothing to be done for 'all'.
make[1]: Leaving directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/4_Finance/BlackScholes'
make[1]: Entering directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/5_Simulations/particles'
>>> WARNING - libGL.so not found, refer to CUDA Samples release notes for how to find and install them. <<<
>>> WARNING - libGLU.so not found, refer to CUDA Samples release notes for how to find and install them. <<<
>>> WARNING - libX11.so not found, refer to CUDA Samples release notes for how to find and install them. <<<
>>> WARNING - libXi.so not found, refer to CUDA Samples release notes for how to find and install them. <<<
>>> WARNING - libXmu.so not found, refer to CUDA Samples release notes for how to find and install them. <<<
>>> WARNING - glu.h not found, refer to CUDA Samples release notes for how to find and install them. <<<
[@] /opt/cuda/bin/nvcc -ccbin g++ -I../../common/inc -m64 -gencode arch=compute_11,code=sm_11 -gencode arch=compute_13,code=sm_13 -gencode arch=compute_20,code=sm_20 -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_37,code=sm_37 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_52,code=sm_52 -gencode arch=compute_52,code=compute_52 -o particleSystem.o -c particleSystem.cpp
[@] /opt/cuda/bin/nvcc -ccbin g++ -I../../common/inc -m64 -gencode arch=compute_11,code=sm_11 -gencode arch=compute_13,code=sm_13 -gencode arch=compute_20,code=sm_20 -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_37,code=sm_37 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_52,code=sm_52 -gencode arch=compute_52,code=compute_52 -o particleSystem_cuda.o -c particleSystem_cuda.cu
[@] /opt/cuda/bin/nvcc -ccbin g++ -I../../common/inc -m64 -gencode arch=compute_11,code=sm_11 -gencode arch=compute_13,code=sm_13 -gencode arch=compute_20,code=sm_20 -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_37,code=sm_37 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_52,code=sm_52 -gencode arch=compute_52,code=compute_52 -o particles.o -c particles.cpp
[@] /opt/cuda/bin/nvcc -ccbin g++ -I../../common/inc -m64 -gencode arch=compute_11,code=sm_11 -gencode arch=compute_13,code=sm_13 -gencode arch=compute_20,code=sm_20 -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_37,code=sm_37 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_52,code=sm_52 -gencode arch=compute_52,code=compute_52 -o render_particles.o -c render_particles.cpp
[@] /opt/cuda/bin/nvcc -ccbin g++ -I../../common/inc -m64 -gencode arch=compute_11,code=sm_11 -gencode arch=compute_13,code=sm_13 -gencode arch=compute_20,code=sm_20 -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_37,code=sm_37 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_52,code=sm_52 -gencode arch=compute_52,code=compute_52 -o shaders.o -c shaders.cpp
[@] /opt/cuda/bin/nvcc -ccbin g++ -m64 -gencode arch=compute_11,code=sm_11 -gencode arch=compute_13,code=sm_13 -gencode arch=compute_20,code=sm_20 -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_37,code=sm_37 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_52,code=sm_52 -gencode arch=compute_52,code=compute_52 -o particles particleSystem.o particleSystem_cuda.o particles.o render_particles.o shaders.o -L../../common/lib/linux/x86_64 -lGL -lGLU -lX11 -lXi -lXmu -lglut -lGLEW
[@] mkdir -p ../../bin/x86_64/linux/release
[@] cp particles ../../bin/x86_64/linux/release
make[1]: Leaving directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/5_Simulations/particles'
make[1]: Entering directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/5_Simulations/smokeParticles'
>>> WARNING - libGL.so not found, refer to CUDA Samples release notes for how to find and install them. <<<
>>> WARNING - libGLU.so not found, refer to CUDA Samples release notes for how to find and install them. <<<
>>> WARNING - libX11.so not found, refer to CUDA Samples release notes for how to find and install them. <<<
>>> WARNING - libXi.so not found, refer to CUDA Samples release notes for how to find and install them. <<<
>>> WARNING - libXmu.so not found, refer to CUDA Samples release notes for how to find and install them. <<<
>>> WARNING - glu.h not found, refer to CUDA Samples release notes for how to find and install them. <<<
[@] /opt/cuda/bin/nvcc -ccbin g++ -I../../common/inc -m64 -gencode arch=compute_11,code=sm_11 -gencode arch=compute_13,code=sm_13 -gencode arch=compute_20,code=sm_20 -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_37,code=sm_37 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_52,code=sm_52 -gencode arch=compute_52,code=compute_52 -o GLSLProgram.o -c GLSLProgram.cpp
[@] /opt/cuda/bin/nvcc -ccbin g++ -I../../common/inc -m64 -gencode arch=compute_11,code=sm_11 -gencode arch=compute_13,code=sm_13 -gencode arch=compute_20,code=sm_20 -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_37,code=sm_37 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_52,code=sm_52 -gencode arch=compute_52,code=compute_52 -o ParticleSystem.o -c ParticleSystem.cpp
[@] /opt/cuda/bin/nvcc -ccbin g++ -I../../common/inc -m64 -gencode arch=compute_11,code=sm_11 -gencode arch=compute_13,code=sm_13 -gencode arch=compute_20,code=sm_20 -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_37,code=sm_37 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_52,code=sm_52 -gencode arch=compute_52,code=compute_52 -o ParticleSystem_cuda.o -c ParticleSystem_cuda.cu
[@] /opt/cuda/bin/nvcc -ccbin g++ -I../../common/inc -m64 -gencode arch=compute_11,code=sm_11 -gencode arch=compute_13,code=sm_13 -gencode arch=compute_20,code=sm_20 -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_37,code=sm_37 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_52,code=sm_52 -gencode arch=compute_52,code=compute_52 -o SmokeRenderer.o -c SmokeRenderer.cpp
[@] /opt/cuda/bin/nvcc -ccbin g++ -I../../common/inc -m64 -gencode arch=compute_11,code=sm_11 -gencode arch=compute_13,code=sm_13 -gencode arch=compute_20,code=sm_20 -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_37,code=sm_37 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_52,code=sm_52 -gencode arch=compute_52,code=compute_52 -o SmokeShaders.o -c SmokeShaders.cpp
[@] /opt/cuda/bin/nvcc -ccbin g++ -I../../common/inc -m64 -gencode arch=compute_11,code=sm_11 -gencode arch=compute_13,code=sm_13 -gencode arch=compute_20,code=sm_20 -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_37,code=sm_37 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_52,code=sm_52 -gencode arch=compute_52,code=compute_52 -o framebufferObject.o -c framebufferObject.cpp
[@] /opt/cuda/bin/nvcc -ccbin g++ -I../../common/inc -m64 -gencode arch=compute_11,code=sm_11 -gencode arch=compute_13,code=sm_13 -gencode arch=compute_20,code=sm_20 -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_37,code=sm_37 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_52,code=sm_52 -gencode arch=compute_52,code=compute_52 -o particleDemo.o -c particleDemo.cpp
[@] /opt/cuda/bin/nvcc -ccbin g++ -I../../common/inc -m64 -gencode arch=compute_11,code=sm_11 -gencode arch=compute_13,code=sm_13 -gencode arch=compute_20,code=sm_20 -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_37,code=sm_37 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_52,code=sm_52 -gencode arch=compute_52,code=compute_52 -o renderbuffer.o -c renderbuffer.cpp
[@] /opt/cuda/bin/nvcc -ccbin g++ -m64 -gencode arch=compute_11,code=sm_11 -gencode arch=compute_13,code=sm_13 -gencode arch=compute_20,code=sm_20 -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_37,code=sm_37 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_52,code=sm_52 -gencode arch=compute_52,code=compute_52 -o smokeParticles GLSLProgram.o ParticleSystem.o ParticleSystem_cuda.o SmokeRenderer.o SmokeShaders.o framebufferObject.o particleDemo.o renderbuffer.o -L../../common/lib/linux/x86_64 -lGL -lGLU -lX11 -lXi -lXmu -lglut -lGLEW
[@] mkdir -p ../../bin/x86_64/linux/release
[@] cp smokeParticles ../../bin/x86_64/linux/release
make[1]: Leaving directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/5_Simulations/smokeParticles'
make[1]: Entering directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/5_Simulations/oceanFFT'
>>> WARNING - libGL.so not found, refer to CUDA Samples release notes for how to find and install them. <<<
>>> WARNING - libGLU.so not found, refer to CUDA Samples release notes for how to find and install them. <<<
>>> WARNING - libX11.so not found, refer to CUDA Samples release notes for how to find and install them. <<<
>>> WARNING - libXi.so not found, refer to CUDA Samples release notes for how to find and install them. <<<
>>> WARNING - libXmu.so not found, refer to CUDA Samples release notes for how to find and install them. <<<
>>> WARNING - glu.h not found, refer to CUDA Samples release notes for how to find and install them. <<<
[@] /opt/cuda/bin/nvcc -ccbin g++ -I../../common/inc -m64 -gencode arch=compute_11,code=sm_11 -gencode arch=compute_20,code=sm_20 -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_37,code=sm_37 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_52,code=sm_52 -gencode arch=compute_52,code=compute_52 -o oceanFFT.o -c oceanFFT.cpp
[@] /opt/cuda/bin/nvcc -ccbin g++ -I../../common/inc -m64 -gencode arch=compute_11,code=sm_11 -gencode arch=compute_20,code=sm_20 -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_37,code=sm_37 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_52,code=sm_52 -gencode arch=compute_52,code=compute_52 -o oceanFFT_kernel.o -c oceanFFT_kernel.cu
[@] /opt/cuda/bin/nvcc -ccbin g++ -m64 -gencode arch=compute_11,code=sm_11 -gencode arch=compute_20,code=sm_20 -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_37,code=sm_37 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_52,code=sm_52 -gencode arch=compute_52,code=compute_52 -o oceanFFT oceanFFT.o oceanFFT_kernel.o -L../../common/lib/linux/x86_64 -lGL -lGLU -lX11 -lXi -lXmu -lglut -lGLEW -lcufft
[@] mkdir -p ../../bin/x86_64/linux/release
[@] cp oceanFFT ../../bin/x86_64/linux/release
make[1]: Leaving directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/5_Simulations/oceanFFT'
make[1]: Entering directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/5_Simulations/fluidsGL'
>>> WARNING - libGL.so not found, refer to CUDA Samples release notes for how to find and install them. <<<
>>> WARNING - libGLU.so not found, refer to CUDA Samples release notes for how to find and install them. <<<
>>> WARNING - libX11.so not found, refer to CUDA Samples release notes for how to find and install them. <<<
>>> WARNING - libXi.so not found, refer to CUDA Samples release notes for how to find and install them. <<<
>>> WARNING - libXmu.so not found, refer to CUDA Samples release notes for how to find and install them. <<<
>>> WARNING - glu.h not found, refer to CUDA Samples release notes for how to find and install them. <<<
[@] /opt/cuda/bin/nvcc -ccbin g++ -I../../common/inc -m64 -gencode arch=compute_11,code=sm_11 -gencode arch=compute_20,code=sm_20 -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_37,code=sm_37 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_52,code=sm_52 -gencode arch=compute_52,code=compute_52 -o fluidsGL.o -c fluidsGL.cpp
[@] /opt/cuda/bin/nvcc -ccbin g++ -I../../common/inc -m64 -gencode arch=compute_11,code=sm_11 -gencode arch=compute_20,code=sm_20 -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_37,code=sm_37 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_52,code=sm_52 -gencode arch=compute_52,code=compute_52 -o fluidsGL_kernels.o -c fluidsGL_kernels.cu
[@] /opt/cuda/bin/nvcc -ccbin g++ -m64 -gencode arch=compute_11,code=sm_11 -gencode arch=compute_20,code=sm_20 -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_37,code=sm_37 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_52,code=sm_52 -gencode arch=compute_52,code=compute_52 -o fluidsGL fluidsGL.o fluidsGL_kernels.o -L../../common/lib/linux/x86_64 -lGL -lGLU -lX11 -lXi -lXmu -lglut -lGLEW -lcufft
[@] mkdir -p ../../bin/x86_64/linux/release
[@] cp fluidsGL ../../bin/x86_64/linux/release
make[1]: Leaving directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/5_Simulations/fluidsGL'
make[1]: Entering directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/5_Simulations/nbody'
>>> WARNING - libGL.so not found, refer to CUDA Samples release notes for how to find and install them. <<<
>>> WARNING - libGLU.so not found, refer to CUDA Samples release notes for how to find and install them. <<<
>>> WARNING - libX11.so not found, refer to CUDA Samples release notes for how to find and install them. <<<
>>> WARNING - libXi.so not found, refer to CUDA Samples release notes for how to find and install them. <<<
>>> WARNING - libXmu.so not found, refer to CUDA Samples release notes for how to find and install them. <<<
>>> WARNING - glu.h not found, refer to CUDA Samples release notes for how to find and install them. <<<
[@] /opt/cuda/bin/nvcc -ccbin g++ -I../../common/inc -m64 -ftz=true -gencode arch=compute_11,code=sm_11 -gencode arch=compute_13,code=sm_13 -gencode arch=compute_20,code=sm_20 -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_37,code=sm_37 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_52,code=sm_52 -gencode arch=compute_52,code=compute_52 -o bodysystemcuda.o -c bodysystemcuda.cu
[@] /opt/cuda/bin/nvcc -ccbin g++ -I../../common/inc -m64 -ftz=true -gencode arch=compute_11,code=sm_11 -gencode arch=compute_13,code=sm_13 -gencode arch=compute_20,code=sm_20 -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_37,code=sm_37 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_52,code=sm_52 -gencode arch=compute_52,code=compute_52 -o nbody.o -c nbody.cpp
[@] /opt/cuda/bin/nvcc -ccbin g++ -I../../common/inc -m64 -ftz=true -gencode arch=compute_11,code=sm_11 -gencode arch=compute_13,code=sm_13 -gencode arch=compute_20,code=sm_20 -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_37,code=sm_37 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_52,code=sm_52 -gencode arch=compute_52,code=compute_52 -o render_particles.o -c render_particles.cpp
[@] /opt/cuda/bin/nvcc -ccbin g++ -m64 -gencode arch=compute_11,code=sm_11 -gencode arch=compute_13,code=sm_13 -gencode arch=compute_20,code=sm_20 -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_37,code=sm_37 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_52,code=sm_52 -gencode arch=compute_52,code=compute_52 -o nbody bodysystemcuda.o nbody.o render_particles.o -L../../common/lib/linux/x86_64 -lGL -lGLU -lX11 -lXi -lXmu -lglut -lGLEW
[@] mkdir -p ../../bin/x86_64/linux/release
[@] cp nbody ../../bin/x86_64/linux/release
make[1]: Leaving directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/5_Simulations/nbody'
make[1]: Entering directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/6_Advanced/lineOfSight'
make[1]: Nothing to be done for 'all'.
make[1]: Leaving directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/6_Advanced/lineOfSight'
make[1]: Entering directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/6_Advanced/alignedTypes'
make[1]: Nothing to be done for 'all'.
make[1]: Leaving directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/6_Advanced/alignedTypes'
make[1]: Entering directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/6_Advanced/fastWalshTransform'
make[1]: Nothing to be done for 'all'.
make[1]: Leaving directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/6_Advanced/fastWalshTransform'
make[1]: Entering directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/6_Advanced/sortingNetworks'
make[1]: Nothing to be done for 'all'.
make[1]: Leaving directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/6_Advanced/sortingNetworks'
make[1]: Entering directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/6_Advanced/cdpQuadtree'
make[1]: Nothing to be done for 'all'.
make[1]: Leaving directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/6_Advanced/cdpQuadtree'
make[1]: Entering directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/6_Advanced/StreamPriorities'
make[1]: Nothing to be done for 'all'.
make[1]: Leaving directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/6_Advanced/StreamPriorities'
make[1]: Entering directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/6_Advanced/newdelete'
make[1]: Nothing to be done for 'all'.
make[1]: Leaving directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/6_Advanced/newdelete'
make[1]: Entering directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/6_Advanced/mergeSort'
make[1]: Nothing to be done for 'all'.
make[1]: Leaving directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/6_Advanced/mergeSort'
make[1]: Entering directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/6_Advanced/eigenvalues'
make[1]: Nothing to be done for 'all'.
make[1]: Leaving directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/6_Advanced/eigenvalues'
make[1]: Entering directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/6_Advanced/shfl_scan'
make[1]: Nothing to be done for 'all'.
make[1]: Leaving directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/6_Advanced/shfl_scan'
make[1]: Entering directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/6_Advanced/reduction'
make[1]: Nothing to be done for 'all'.
make[1]: Leaving directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/6_Advanced/reduction'
make[1]: Entering directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/6_Advanced/radixSortThrust'
make[1]: Nothing to be done for 'all'.
make[1]: Leaving directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/6_Advanced/radixSortThrust'
make[1]: Entering directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/6_Advanced/threadFenceReduction'
make[1]: Nothing to be done for 'all'.
make[1]: Leaving directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/6_Advanced/threadFenceReduction'
make[1]: Entering directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/6_Advanced/ptxjit'
make[1]: Nothing to be done for 'all'.
make[1]: Leaving directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/6_Advanced/ptxjit'
make[1]: Entering directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/6_Advanced/scan'
make[1]: Nothing to be done for 'all'.
make[1]: Leaving directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/6_Advanced/scan'
make[1]: Entering directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/6_Advanced/scalarProd'
make[1]: Nothing to be done for 'all'.
make[1]: Leaving directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/6_Advanced/scalarProd'
make[1]: Entering directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/6_Advanced/FDTD3d'
make[1]: Nothing to be done for 'all'.
make[1]: Leaving directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/6_Advanced/FDTD3d'
make[1]: Entering directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/6_Advanced/matrixMulDynlinkJIT'
make[1]: Nothing to be done for 'all'.
make[1]: Leaving directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/6_Advanced/matrixMulDynlinkJIT'
make[1]: Entering directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/6_Advanced/simpleHyperQ'
make[1]: Nothing to be done for 'all'.
make[1]: Leaving directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/6_Advanced/simpleHyperQ'
make[1]: Entering directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/6_Advanced/interval'
make[1]: Nothing to be done for 'all'.
make[1]: Leaving directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/6_Advanced/interval'
make[1]: Entering directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/6_Advanced/concurrentKernels'
make[1]: Nothing to be done for 'all'.
make[1]: Leaving directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/6_Advanced/concurrentKernels'
make[1]: Entering directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/6_Advanced/FunctionPointers'
>>> WARNING - libGL.so not found, refer to CUDA Samples release notes for how to find and install them. <<<
>>> WARNING - libGLU.so not found, refer to CUDA Samples release notes for how to find and install them. <<<
>>> WARNING - libX11.so not found, refer to CUDA Samples release notes for how to find and install them. <<<
>>> WARNING - libXi.so not found, refer to CUDA Samples release notes for how to find and install them. <<<
>>> WARNING - libXmu.so not found, refer to CUDA Samples release notes for how to find and install them. <<<
>>> WARNING - glu.h not found, refer to CUDA Samples release notes for how to find and install them. <<<
[@] /opt/cuda/bin/nvcc -ccbin g++ -I../../common/inc -m64 -gencode arch=compute_20,code=sm_20 -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_37,code=sm_37 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_52,code=sm_52 -gencode arch=compute_52,code=compute_52 -o FunctionPointers.o -c FunctionPointers.cpp
[@] /opt/cuda/bin/nvcc -ccbin g++ -I../../common/inc -m64 -gencode arch=compute_20,code=sm_20 -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_37,code=sm_37 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_52,code=sm_52 -gencode arch=compute_52,code=compute_52 -o FunctionPointers_kernels.o -c FunctionPointers_kernels.cu
[@] /opt/cuda/bin/nvcc -ccbin g++ -m64 -gencode arch=compute_20,code=sm_20 -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_37,code=sm_37 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_52,code=sm_52 -gencode arch=compute_52,code=compute_52 -o FunctionPointers FunctionPointers.o FunctionPointers_kernels.o -L../../common/lib/linux/x86_64 -lGL -lGLU -lX11 -lXi -lXmu -lglut -lGLEW
[@] mkdir -p ../../bin/x86_64/linux/release
[@] cp FunctionPointers ../../bin/x86_64/linux/release
make[1]: Leaving directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/6_Advanced/FunctionPointers'
make[1]: Entering directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/6_Advanced/cdpBezierTessellation'
make[1]: Nothing to be done for 'all'.
make[1]: Leaving directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/6_Advanced/cdpBezierTessellation'
make[1]: Entering directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/6_Advanced/segmentationTreeThrust'
make[1]: Nothing to be done for 'all'.
make[1]: Leaving directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/6_Advanced/segmentationTreeThrust'
make[1]: Entering directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/6_Advanced/threadMigration'
make[1]: Nothing to be done for 'all'.
make[1]: Leaving directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/6_Advanced/threadMigration'
make[1]: Entering directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/6_Advanced/cdpAdvancedQuicksort'
make[1]: Nothing to be done for 'all'.
make[1]: Leaving directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/6_Advanced/cdpAdvancedQuicksort'
make[1]: Entering directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/6_Advanced/cdpLUDecomposition'
make[1]: Nothing to be done for 'all'.
make[1]: Leaving directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/6_Advanced/cdpLUDecomposition'
make[1]: Entering directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/6_Advanced/transpose'
make[1]: Nothing to be done for 'all'.
make[1]: Leaving directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/6_Advanced/transpose'
make[1]: Entering directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/7_CUDALibraries/imageSegmentationNPP'
make[1]: Nothing to be done for 'all'.
make[1]: Leaving directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/7_CUDALibraries/imageSegmentationNPP'
make[1]: Entering directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/7_CUDALibraries/simpleCUFFT_callback'
make[1]: Nothing to be done for 'all'.
make[1]: Leaving directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/7_CUDALibraries/simpleCUFFT_callback'
make[1]: Entering directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/7_CUDALibraries/conjugateGradient'
make[1]: Nothing to be done for 'all'.
make[1]: Leaving directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/7_CUDALibraries/conjugateGradient'
make[1]: Entering directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/7_CUDALibraries/freeImageInteropNPP'
make[1]: Nothing to be done for 'all'.
make[1]: Leaving directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/7_CUDALibraries/freeImageInteropNPP'
make[1]: Entering directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/7_CUDALibraries/MC_EstimatePiQ'
make[1]: Nothing to be done for 'all'.
make[1]: Leaving directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/7_CUDALibraries/MC_EstimatePiQ'
make[1]: Entering directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/7_CUDALibraries/simpleCUFFT_2d_MGPU'
make[1]: Nothing to be done for 'all'.
make[1]: Leaving directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/7_CUDALibraries/simpleCUFFT_2d_MGPU'
make[1]: Entering directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/7_CUDALibraries/MersenneTwisterGP11213'
make[1]: Nothing to be done for 'all'.
make[1]: Leaving directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/7_CUDALibraries/MersenneTwisterGP11213'
make[1]: Entering directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/7_CUDALibraries/simpleCUFFT_MGPU'
make[1]: Nothing to be done for 'all'.
make[1]: Leaving directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/7_CUDALibraries/simpleCUFFT_MGPU'
make[1]: Entering directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/7_CUDALibraries/grabcutNPP'
>>> WARNING - libGL.so not found, refer to CUDA Samples release notes for how to find and install them. <<<
>>> WARNING - libGLU.so not found, refer to CUDA Samples release notes for how to find and install them. <<<
>>> WARNING - libX11.so not found, refer to CUDA Samples release notes for how to find and install them. <<<
>>> WARNING - libXi.so not found, refer to CUDA Samples release notes for how to find and install them. <<<
>>> WARNING - libXmu.so not found, refer to CUDA Samples release notes for how to find and install them. <<<
>>> WARNING - glu.h not found, refer to CUDA Samples release notes for how to find and install them. <<<
[@] /opt/cuda/bin/nvcc -ccbin g++ -I../../common/inc -I../common/UtilNPP -I../common/FreeImage/include -m64 -gencode arch=compute_11,code=sm_11 -gencode arch=compute_20,code=sm_20 -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_37,code=sm_37 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_52,code=sm_52 -gencode arch=compute_52,code=compute_52 -o GrabCut.o -c GrabCut.cpp
[@] /opt/cuda/bin/nvcc -ccbin g++ -I../../common/inc -I../common/UtilNPP -I../common/FreeImage/include -m64 -gencode arch=compute_11,code=sm_11 -gencode arch=compute_20,code=sm_20 -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_37,code=sm_37 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_52,code=sm_52 -gencode arch=compute_52,code=compute_52 -o GrabcutGMM.o -c GrabcutGMM.cu
[@] /opt/cuda/bin/nvcc -ccbin g++ -I../../common/inc -I../common/UtilNPP -I../common/FreeImage/include -m64 -gencode arch=compute_11,code=sm_11 -gencode arch=compute_20,code=sm_20 -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_37,code=sm_37 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_52,code=sm_52 -gencode arch=compute_52,code=compute_52 -o GrabcutHistogram.o -c GrabcutHistogram.cu
[@] /opt/cuda/bin/nvcc -ccbin g++ -I../../common/inc -I../common/UtilNPP -I../common/FreeImage/include -m64 -gencode arch=compute_11,code=sm_11 -gencode arch=compute_20,code=sm_20 -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_37,code=sm_37 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_52,code=sm_52 -gencode arch=compute_52,code=compute_52 -o GrabcutMain.o -c GrabcutMain.cpp
[@] /opt/cuda/bin/nvcc -ccbin g++ -I../../common/inc -I../common/UtilNPP -I../common/FreeImage/include -m64 -gencode arch=compute_11,code=sm_11 -gencode arch=compute_20,code=sm_20 -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_37,code=sm_37 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_52,code=sm_52 -gencode arch=compute_52,code=compute_52 -o GrabcutUtil.o -c GrabcutUtil.cu
[@] /opt/cuda/bin/nvcc -ccbin g++ -m64 -gencode arch=compute_11,code=sm_11 -gencode arch=compute_20,code=sm_20 -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_37,code=sm_37 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_52,code=sm_52 -gencode arch=compute_52,code=compute_52 -o grabcutNPP GrabCut.o GrabcutGMM.o GrabcutHistogram.o GrabcutMain.o GrabcutUtil.o -L../../common/lib/linux/x86_64 -lGL -lGLU -lX11 -lXi -lXmu -lglut -lGLEW -L../common/FreeImage/lib -L../common/FreeImage/lib/linux -L../common/FreeImage/lib/linux/x86_64 -lnppi -lnppc -lfreeimage
[@] mkdir -p ../../bin/x86_64/linux/release
[@] cp grabcutNPP ../../bin/x86_64/linux/release
make[1]: Leaving directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/7_CUDALibraries/grabcutNPP'
make[1]: Entering directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/7_CUDALibraries/simpleCUFFT'
make[1]: Nothing to be done for 'all'.
make[1]: Leaving directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/7_CUDALibraries/simpleCUFFT'
make[1]: Entering directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/7_CUDALibraries/cuHook'
make[1]: Nothing to be done for 'all'.
make[1]: Leaving directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/7_CUDALibraries/cuHook'
make[1]: Entering directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/7_CUDALibraries/conjugateGradientUM'
make[1]: Nothing to be done for 'all'.
make[1]: Leaving directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/7_CUDALibraries/conjugateGradientUM'
make[1]: Entering directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/7_CUDALibraries/boxFilterNPP'
make[1]: Nothing to be done for 'all'.
make[1]: Leaving directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/7_CUDALibraries/boxFilterNPP'
make[1]: Entering directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/7_CUDALibraries/MC_EstimatePiInlineQ'
"/opt/cuda"/bin/nvcc -ccbin g++ -I../../common/inc  -m64     -gencode arch=compute_13,code=sm_13 -gencode arch=compute_20,code=sm_20 -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_37,code=sm_37 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_52,code=sm_52 -gencode arch=compute_52,code=compute_52 -o main.o -c src/main.cpp
nvcc warning : The 'compute_11', 'compute_12', 'compute_13', 'sm_11', 'sm_12', and 'sm_13' architectures are deprecated, and may be removed in a future release.
"/opt/cuda"/bin/nvcc -ccbin g++ -I../../common/inc  -m64     -gencode arch=compute_13,code=sm_13 -gencode arch=compute_20,code=sm_20 -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_37,code=sm_37 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_52,code=sm_52 -gencode arch=compute_52,code=compute_52 -o piestimator.o -c src/piestimator.cu
nvcc warning : The 'compute_11', 'compute_12', 'compute_13', 'sm_11', 'sm_12', and 'sm_13' architectures are deprecated, and may be removed in a future release.
"/opt/cuda"/bin/nvcc -ccbin g++ -I../../common/inc  -m64     -gencode arch=compute_13,code=sm_13 -gencode arch=compute_20,code=sm_20 -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_37,code=sm_37 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_52,code=sm_52 -gencode arch=compute_52,code=compute_52 -o test.o -c src/test.cpp
nvcc warning : The 'compute_11', 'compute_12', 'compute_13', 'sm_11', 'sm_12', and 'sm_13' architectures are deprecated, and may be removed in a future release.
"/opt/cuda"/bin/nvcc -ccbin g++   -m64       -gencode arch=compute_13,code=sm_13 -gencode arch=compute_20,code=sm_20 -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_37,code=sm_37 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_52,code=sm_52 -gencode arch=compute_52,code=compute_52 -o MC_EstimatePiInlineQ main.o piestimator.o test.o  -lcurand
nvcc warning : The 'compute_11', 'compute_12', 'compute_13', 'sm_11', 'sm_12', and 'sm_13' architectures are deprecated, and may be removed in a future release.
mkdir -p ../../bin/x86_64/linux/release
cp MC_EstimatePiInlineQ ../../bin/x86_64/linux/release
make[1]: Leaving directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/7_CUDALibraries/MC_EstimatePiInlineQ'
make[1]: Entering directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/7_CUDALibraries/MC_SingleAsianOptionP'
make[1]: Nothing to be done for 'all'.
make[1]: Leaving directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/7_CUDALibraries/MC_SingleAsianOptionP'
make[1]: Entering directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/7_CUDALibraries/simpleDevLibCUBLAS'
make[1]: Nothing to be done for 'all'.
make[1]: Leaving directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/7_CUDALibraries/simpleDevLibCUBLAS'
make[1]: Entering directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/7_CUDALibraries/jpegNPP'
make[1]: Nothing to be done for 'all'.
make[1]: Leaving directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/7_CUDALibraries/jpegNPP'
make[1]: Entering directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/7_CUDALibraries/MC_EstimatePiInlineP'
make[1]: Nothing to be done for 'all'.
make[1]: Leaving directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/7_CUDALibraries/MC_EstimatePiInlineP'
make[1]: Entering directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/7_CUDALibraries/histEqualizationNPP'
make[1]: Nothing to be done for 'all'.
make[1]: Leaving directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/7_CUDALibraries/histEqualizationNPP'
make[1]: Entering directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/7_CUDALibraries/randomFog'
>>> WARNING - libGL.so not found, refer to CUDA Samples release notes for how to find and install them. <<<
>>> WARNING - libGLU.so not found, refer to CUDA Samples release notes for how to find and install them. <<<
>>> WARNING - libX11.so not found, refer to CUDA Samples release notes for how to find and install them. <<<
>>> WARNING - libXi.so not found, refer to CUDA Samples release notes for how to find and install them. <<<
>>> WARNING - libXmu.so not found, refer to CUDA Samples release notes for how to find and install them. <<<
>>> WARNING - glu.h not found, refer to CUDA Samples release notes for how to find and install them. <<<
[@] /opt/cuda/bin/nvcc -ccbin g++ -I../../common/inc -m64 -Xcompiler -fpermissive -gencode arch=compute_11,code=compute_11 -o randomFog.o -c randomFog.cpp
[@] /opt/cuda/bin/nvcc -ccbin g++ -I../../common/inc -m64 -Xcompiler -fpermissive -gencode arch=compute_11,code=compute_11 -o rng.o -c rng.cpp
[@] /opt/cuda/bin/nvcc -ccbin g++ -m64 -gencode arch=compute_11,code=compute_11 -o randomFog randomFog.o rng.o -L../../common/lib/linux/x86_64 -lGL -lGLU -lX11 -lXi -lXmu -lglut -lGLEW -lcurand
[@] mkdir -p ../../bin/x86_64/linux/release
[@] cp randomFog ../../bin/x86_64/linux/release
make[1]: Leaving directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/7_CUDALibraries/randomFog'
make[1]: Entering directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/7_CUDALibraries/MC_EstimatePiP'
make[1]: Nothing to be done for 'all'.
make[1]: Leaving directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/7_CUDALibraries/MC_EstimatePiP'
make[1]: Entering directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/7_CUDALibraries/batchCUBLAS'
make[1]: Nothing to be done for 'all'.
make[1]: Leaving directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/7_CUDALibraries/batchCUBLAS'
make[1]: Entering directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/7_CUDALibraries/conjugateGradientPrecond'
make[1]: Nothing to be done for 'all'.
make[1]: Leaving directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/7_CUDALibraries/conjugateGradientPrecond'
make[1]: Entering directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/7_CUDALibraries/simpleCUBLAS'
make[1]: Nothing to be done for 'all'.
make[1]: Leaving directory '/opt/cuda/samples2/NVIDIA_CUDA-6.5_Samples/7_CUDALibraries/simpleCUBLAS'
Finished building CUDA samples
#+end_src


I force the GPU, and it accepts
#+begin_src sh :noeval
THEANO_FLAGS=mode=FAST_RUN,device=gpu,floatX=float32,force_device=True python theano_gpu_test.py
#Using gpu device 0: GeForce GTX 550 Ti
#[GpuElemwise{exp,no_inplace}(<CudaNdarrayType(float32, vector)>), HostFromGpu(GpuElemwise{exp,no_inplace}.0)]
#Looping 1000 times took 0.438356876373 seconds
#Result is [ 1.23178029  1.61879349  1.52278066 ...,  2.20771813  2.29967761
#  1.62323296]
#Used the gpu
#+end_src

So I add that to my .theanorc and try fitting model

Doesn't seem to work. Suuuper slow still. Could just be
settings. See [[Tune GPU]].


*** WTH . . . 
    - So, theano is running on gpu using force flag
    - Tiny bit of memory load, and when I try two processes
      to use gpu I get this error

#+begin_src 
INFO (theano.gof.compilelock): Waiting for existing lock by process '9511' (I am process '7923')
INFO:theano.gof.compilelock:Waiting for existing lock by process '9511' (I am process '7923')
INFO (theano.gof.compilelock): To manually release the lock, delete /home/jotham/.theano/compiledir_Linux-3.18.6-1-ARCH-x86_64-with-glibc2.2.5--2.7.9-64/lock_dir
INFO:theano.gof.compilelock:To manually release the lock, delete /home/jotham/.theano/compiledir_Linux-3.18.6-1-ARCH-x86_64-with-glibc2.2.5--2.7.9-64/lock_dir
#+end_src

    Theano tests ran with following output
#+begin_src sh :noeval
THEANO_FLAGS=mode=FAST_RUN,device=cpu,floatX=float32 python -c 'import theano; theano.test()' >> theano_test.txt
#+end_src
#+begin_src 
THEANO_FLAGS=mode=FAST_RUN,device=cpu,floatX=float32 python -c 'import theano; theano.test()' >> theano_test.txt
........................................E.............../home/jotham/venvs/2014-12-20_datascibowl/lib/python2.7/site-packages/theano/compile/tests/test_inplace_opt_for_value.py:170: UserWarning: theano modules are deprecated and will be removed in release 0.7
  super(ExampleRNN, self).__init__()
/home/jotham/venvs/2014-12-20_datascibowl/lib/python2.7/site-packages/theano/tensor/subtensor.py:110: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.
  start in [None, 0] or
/home/jotham/venvs/2014-12-20_datascibowl/lib/python2.7/site-packages/theano/tensor/subtensor.py:114: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.
  stop in [None, length, maxsize] or
...................................................................................................../home/jotham/venvs/2014-12-20_datascibowl/lib/python2.7/site-packages/theano/scan_module/scan_perform_ext.py:85: RuntimeWarning: numpy.ndarray size changed, may indicate binary incompatibility
  from scan_perform.scan_perform import *
................................................................................................................................................/home/jotham/venvs/2014-12-20_datascibowl/lib/python2.7/site-packages/theano/tensor/opt.py:2165: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.
  if (replace_x == replace_y and
......................................EE..................................................................E............................./home/jotham/venvs/2014-12-20_datascibowl/lib/python2.7/site-packages/theano/tensor/subtensor.py:190: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.
  if stop in [None, maxsize]:
...........E..............E................................................/home/jotham/venvs/2014-12-20_datascibowl/lib/python2.7/site-packages/theano/sparse/basic.py:87: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.
  return numpy.all(a == b)
................./home/jotham/venvs/2014-12-20_datascibowl/lib/python2.7/site-packages/scipy/sparse/data.py:63: ComplexWarning: Casting complex values to real discards the imaginary part
  return self._with_data(self.data.astype(t))
/home/jotham/venvs/2014-12-20_datascibowl/lib/python2.7/site-packages/theano/sparse/tests/test_basic.py:2128: ComplexWarning: Casting complex values to real discards the imaginary part
  expected = data.toarray().astype(o_dtype)
...../home/jotham/venvs/2014-12-20_datascibowl/lib/python2.7/site-packages/scipy/sparse/compressed.py:698: SparseEfficiencyWarning: Changing the sparsity structure of a csc_matrix is expensive. lil_matrix is more efficient.
  SparseEfficiencyWarning)
/home/jotham/venvs/2014-12-20_datascibowl/lib/python2.7/site-packages/scipy/sparse/compressed.py:698: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.
  SparseEfficiencyWarning)
...................................................................................................../home/jotham/venvs/2014-12-20_datascibowl/lib/python2.7/site-packages/theano/tensor/subtensor.py:1469: UserWarning: DEPRECATION WARNING: AdvancedSubtensor1, you are using an old interface to the sparse grad. You should use theano.sparse_grad(a_tensor[an_int_vector]). 
  "DEPRECATION WARNING: AdvancedSubtensor1, you are using"
.................................................................................................................................................................................................................................INFO (theano.gof.compilelock): Waiting for existing lock by process '21429' (I am process '9511')
INFO (theano.gof.compilelock): To manually release the lock, delete /home/jotham/.theano/compiledir_Linux-3.18.6-1-ARCH-x86_64-with-glibc2.2.5--2.7.9-64/lock_dir
............................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................E........................................................................................................................................................................................................................................................................................................................E..EEEE.E............/home/jotham/venvs/2014-12-20_datascibowl/lib/python2.7/site-packages/theano/compile/function_module.py:579: ComplexWarning: Casting complex values to real discards the imaginary part
  outputs = self.fn()
....t......................................................E........................../home/jotham/venvs/2014-12-20_datascibowl/lib/python2.7/site-packages/theano/tensor/tests/test_naacl09.py:69: UserWarning: RandomStreams is deprecated and will be removed in release 0.7. Use shared_randomstreams.RandomStreams or MRG_RandomStreams instead.
  self.random = T.randomstreams.RandomStreams()
E.....................................................................................................E......E.............................................................................................................................................../home/jotham/venvs/2014-12-20_datascibowl/lib/python2.7/site-packages/theano/tensor/var.py:359: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.
  if arg != numpy.newaxis:
......................................................................................................EE.............................................
======================================================================
ERROR: test_none (theano.compile.tests.test_function_module.T_function)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/jotham/venvs/2014-12-20_datascibowl/lib/python2.7/site-packages/theano/compile/tests/test_function_module.py", line 42, in test_none
    raise KnownFailureTest('See #254: Using None as function output leads to [] return value')
KnownFailureTest: See #254: Using None as function output leads to [] return value

======================================================================
ERROR: test002_generator_one_scalar_output (theano.sandbox.scan_module.tests.test_scan.TestScan)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/jotham/venvs/2014-12-20_datascibowl/lib/python2.7/site-packages/theano/sandbox/scan_module/tests/test_scan.py", line 474, in test002_generator_one_scalar_output
    raise KnownFailureTest('Work-in-progress sandbox ScanOp is not fully '
KnownFailureTest: Work-in-progress sandbox ScanOp is not fully functional yet

======================================================================
ERROR: test003_one_sequence_one_output_and_weights (theano.sandbox.scan_module.tests.test_scan.TestScan)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/jotham/venvs/2014-12-20_datascibowl/lib/python2.7/site-packages/theano/sandbox/scan_module/tests/test_scan.py", line 512, in test003_one_sequence_one_output_and_weights
    raise KnownFailureTest('Work-in-progress sandbox ScanOp is not fully '
KnownFailureTest: Work-in-progress sandbox ScanOp is not fully functional yet

======================================================================
ERROR: test_alloc_inputs2 (theano.scan_module.tests.test_scan.T_Scan)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/jotham/venvs/2014-12-20_datascibowl/lib/python2.7/site-packages/theano/scan_module/tests/test_scan.py", line 2844, in test_alloc_inputs2
    "This tests depends on an optimization for scan "
KnownFailureTest: This tests depends on an optimization for scan that has not been implemented yet.

======================================================================
ERROR: test_infershape_seq_shorter_nsteps (theano.scan_module.tests.test_scan.T_Scan)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/jotham/venvs/2014-12-20_datascibowl/lib/python2.7/site-packages/theano/scan_module/tests/test_scan.py", line 3040, in test_infershape_seq_shorter_nsteps
    raise KnownFailureTest('This is a generic problem with infershape'
KnownFailureTest: This is a generic problem with infershape that has to be discussed and figured out

======================================================================
ERROR: test_outputs_info_not_typed (theano.scan_module.tests.test_scan.T_Scan)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/jotham/venvs/2014-12-20_datascibowl/lib/python2.7/site-packages/numpy/testing/decorators.py", line 213, in knownfailer
    raise KnownFailureTest(msg)
KnownFailureTest: This test fails because not typed outputs_info are always gived the smallest dtype. There is no upcast of outputs_info in scan for now.

======================================================================
ERROR: test_arithmetic_cast (theano.tensor.tests.test_basic.test_arithmetic_cast)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/jotham/venvs/2014-12-20_datascibowl/lib/python2.7/site-packages/theano/tensor/tests/test_basic.py", line 5583, in test_arithmetic_cast
    raise KnownFailureTest('Known issue with '
KnownFailureTest: Known issue with numpy >= 1.6.x see #761

======================================================================
ERROR: test_abs_grad (theano.tensor.tests.test_complex.TestRealImag)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/jotham/venvs/2014-12-20_datascibowl/lib/python2.7/site-packages/numpy/testing/decorators.py", line 213, in knownfailer
    raise KnownFailureTest(msg)
KnownFailureTest: Complex grads not enabled, see #178

======================================================================
ERROR: test_complex_grads (theano.tensor.tests.test_complex.TestRealImag)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/jotham/venvs/2014-12-20_datascibowl/lib/python2.7/site-packages/numpy/testing/decorators.py", line 213, in knownfailer
    raise KnownFailureTest(msg)
KnownFailureTest: Complex grads not enabled, see #178

======================================================================
ERROR: test_mul_mixed (theano.tensor.tests.test_complex.TestRealImag)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/jotham/venvs/2014-12-20_datascibowl/lib/python2.7/site-packages/numpy/testing/decorators.py", line 213, in knownfailer
    raise KnownFailureTest(msg)
KnownFailureTest: Complex grads not enabled, see #178

======================================================================
ERROR: test_mul_mixed0 (theano.tensor.tests.test_complex.TestRealImag)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/jotham/venvs/2014-12-20_datascibowl/lib/python2.7/site-packages/numpy/testing/decorators.py", line 213, in knownfailer
    raise KnownFailureTest(msg)
KnownFailureTest: Complex grads not enabled, see #178

======================================================================
ERROR: test_mul_mixed1 (theano.tensor.tests.test_complex.TestRealImag)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/jotham/venvs/2014-12-20_datascibowl/lib/python2.7/site-packages/numpy/testing/decorators.py", line 213, in knownfailer
    raise KnownFailureTest(msg)
KnownFailureTest: Complex grads not enabled, see #178

======================================================================
ERROR: test_polar_grads (theano.tensor.tests.test_complex.TestRealImag)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/jotham/venvs/2014-12-20_datascibowl/lib/python2.7/site-packages/numpy/testing/decorators.py", line 213, in knownfailer
    raise KnownFailureTest(msg)
KnownFailureTest: Complex grads not enabled, see #178

======================================================================
ERROR: test_gradient (theano.tensor.tests.test_fourier.TestFourier)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/jotham/venvs/2014-12-20_datascibowl/lib/python2.7/site-packages/numpy/testing/decorators.py", line 213, in knownfailer
    raise KnownFailureTest(msg)
KnownFailureTest: Complex grads not enabled, see #178

======================================================================
ERROR: theano.tensor.tests.test_naacl09.test_naacl_model
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/jotham/venvs/2014-12-20_datascibowl/lib/python2.7/site-packages/nose/case.py", line 197, in runTest
    self.test(*self.arg)
  File "/home/jotham/venvs/2014-12-20_datascibowl/lib/python2.7/site-packages/theano/tensor/tests/test_naacl09.py", line 613, in test_naacl_model
    raise KnownFailureTest("Deprecated compile.module fails to "
KnownFailureTest: Deprecated compile.module fails to give a sensible warning when updates to a variable have the wrong type

======================================================================
ERROR: theano.tensor.tests.test_opt.test_log_add
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/jotham/venvs/2014-12-20_datascibowl/lib/python2.7/site-packages/nose/case.py", line 197, in runTest
    self.test(*self.arg)
  File "/home/jotham/venvs/2014-12-20_datascibowl/lib/python2.7/site-packages/theano/tensor/tests/test_opt.py", line 1508, in test_log_add
    raise KnownFailureTest(('log(add(exp)) is not stabilized when adding '
KnownFailureTest: log(add(exp)) is not stabilized when adding more than 2 elements, see #623

======================================================================
ERROR: Currently Theano enable the constant_folding optimization before stabilization optimization.
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/jotham/venvs/2014-12-20_datascibowl/lib/python2.7/site-packages/nose/case.py", line 197, in runTest
    self.test(*self.arg)
  File "/home/jotham/venvs/2014-12-20_datascibowl/lib/python2.7/site-packages/theano/tensor/tests/test_opt.py", line 3068, in test_constant_get_stabilized
    "Theano optimizes constant before stabilization. "
KnownFailureTest: Theano optimizes constant before stabilization. This breaks stabilization optimization in some cases. See #504.

======================================================================
ERROR: test_dot (theano.tests.test_rop.test_RopLop)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/jotham/venvs/2014-12-20_datascibowl/lib/python2.7/site-packages/theano/tests/test_rop.py", line 277, in test_dot
    self.check_rop_lop(tensor.dot(self.x, W), self.in_shape)
  File "/home/jotham/venvs/2014-12-20_datascibowl/lib/python2.7/site-packages/theano/tests/test_rop.py", line 191, in check_rop_lop
    raise KnownFailureTest("Rop doesn't handle non-differentiable "
KnownFailureTest: Rop doesn't handle non-differentiable inputs correctly. Bug exposed by fixing Add.grad method.

======================================================================
ERROR: test_elemwise0 (theano.tests.test_rop.test_RopLop)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/jotham/venvs/2014-12-20_datascibowl/lib/python2.7/site-packages/theano/tests/test_rop.py", line 280, in test_elemwise0
    self.check_rop_lop((self.x + 1) ** 2, self.in_shape)
  File "/home/jotham/venvs/2014-12-20_datascibowl/lib/python2.7/site-packages/theano/tests/test_rop.py", line 191, in check_rop_lop
    raise KnownFailureTest("Rop doesn't handle non-differentiable "
KnownFailureTest: Rop doesn't handle non-differentiable inputs correctly. Bug exposed by fixing Add.grad method.

----------------------------------------------------------------------
Ran 2441 tests in 3104.784s

#+end_src

** DONE Run CNN mnist tutorial
   CLOSED: [2015-02-24 Tue 06:59]
   :LOGBOOK:  
   - State "DONE"       from "WAITING"    [2015-02-24 Tue 06:59]
   - State "WAITING"    from ""           [2015-02-23 Mon 22:05] \\
     - running
   :END:      
   - power went out :(
   - epochs were somewhat fast, however

** DONE Test whole ipynb flow on desktop
   CLOSED: [2015-02-23 Mon 22:07]
   :LOGBOOK:  
   - State "DONE"       from "NEXT"       [2015-02-23 Mon 22:07]
   - State "NEXT"       from ""           [2015-02-22 Sun 21:17]
   :END:      
   - did this on softreg shuf_ctr_sgd_10
   - see ipynb_work
#+begin_src sh :results verbatim code replace output 
ls ipynb_work
#+end_src

#+RESULTS:
#+BEGIN_SRC sh
softreg_shuf_ctr_sgd_06_complete.ipynb
softreg_shuf_ctr_sgd_10.ipynb
softreg_shuf_ctr_sgd_bestnll_10.pkl
softreg_shuf_ctr_sgd_last_10.pkl
sr_train_06.yaml
sr_train_10.yaml
#+END_SRC

** DONE change MonitorBasedSaveBest to use nll
   CLOSED: [2015-02-23 Mon 22:08]
   :LOGBOOK:  
   - State "DONE"       from "NEXT"       [2015-02-23 Mon 22:08]
   - State "NEXT"       from ""           [2015-02-22 Sun 21:18]
   :END:      
   See [[Test whole ipynb flow on desktop]]
** DONE Don't hardcode path into datasetclass
   CLOSED: [2015-02-24 Tue 07:16]
   :LOGBOOK:  
   - State "DONE"       from "NEXT"       [2015-02-24 Tue 07:16]
   - State "NEXT"       from ""           [2015-02-22 Sun 21:21]
   :END:      
   - use pylearn_data_path
** NEXT [#A] Data augmentation - weekend
   :LOGBOOK:  
   - State "NEXT"       from "TODO"       [2015-02-22 Sun 21:14]
   :END:      
   - https://github.com/benanne/kaggle-galaxies

** TODO [#B] Then simple BGD and SGD again on softmax again
   - using augmented data
   - on laptop
   
** DONE Ask how to know if pylearn really using GPU?
   CLOSED: [2015-02-25 Wed 19:38]
   :LOGBOOK:  
   - State "DONE"       from "WAITING"    [2015-02-25 Wed 19:38]
   - State "WAITING"    from "DONE"       [2015-02-23 Mon 22:03] \\
     - see if anything
   - State "DONE"       from ""           [2015-02-23 Mon 22:03]
   :END:      
   - could try a job with and without gpu flags
   - https://groups.google.com/forum/#!topic/pylearn-users/aZ43lHLpDT0
** NEXT [#A] Use CNN [3/4]
   :LOGBOOK:  
   - State "NEXT"       from "TODO"       [2015-02-25 Wed 08:16]
   - State "NEXT"       from ""           [2015-02-16 Mon 11:46]
   :END:      
   - layers
   - [[http://www.cifasis-conicet.gov.ar/granitto/ECI2014/3.ApunteNeuralNetworks.pdf][some more tips and tricks]]
*** DONE first check out multilayer perceptrons
    CLOSED: [2015-02-25 Wed 08:19]
    :LOGBOOK:  
    - State "DONE"       from "TODO"       [2015-02-25 Wed 08:19]
    :END:      
     - http://localhost:8888/notebooks/pylearn2_fork/pylearn2/scripts/tutorials/multilayer_perceptron/multilayer_perceptron.ipynb
     - The MLP makes a weak assumption on the model, that,
       generally speaking, the inputs map to outputs via the
       composition of several functions.

       A related issue with MLPs is that they have many
       configuration options. The model itself imposes
       design decisions such as what type of function to use
       for each layer, the dimensionality of each layer.
       Also, the log likelihood is no longer generally
       concave, so the choice of optimization procedure
       matters more than it did with softmax regression.
       These configuration options are known as
       "hyperparameters." Choosing the right hyperparameters
       is an open and exciting research problem

       To show how the MLP is specified via the yaml

       Model: !obj:pylearn2.models.mlp.MLP {
           layers: [
                 !obj:pylearn2.models.mlp.Sigmoid {
                     layer_name: 'h0',
                     dim: 500,
                     sparse_init: 15,
                 }, !obj:pylearn2.models.mlp.Softmax {
                     layer_name: 'y',
                     n_classes: 10,
                     irange: 0.
                 }
                ],
           nvis: 784,
       },

     see
     
#+begin_src sh
ls ipynb_work/*mlp*
#+end_src

#+RESULTS:
: ipynb_work/mlp_01.yaml

*** DONE Fit a MLP
    CLOSED: [2015-02-25 Wed 22:19]
    :LOGBOOK:  
    - State "DONE"       from "NEXT"       [2015-02-25 Wed 22:19]
    - State "NEXT"       from ""           [2015-02-25 Wed 08:19]
    :END:      
Some new parameters to define

Model MLP
~layer_name~
~dim~
~sparse_init~
~n_classes~
~irange~

Algorithm BGD
~updates per batch~
~conjugate~


with an interlude for emacs greatness: this failed as there
was tabs in the yaml. C-x h (highlight all) and M-x untabify
<RET> to replace all tabs with whitespace.
    
#+begin_src sh :results verbatim code replace output
cat ipynb_work/mlp_01.yaml
#+end_src

#+RESULTS:
#+BEGIN_SRC
!obj:pylearn2.train.Train {
    dataset: &train !obj:pylearn2.datasets.datascibowl.DataSciBowl {
        which_set: 'train',
        start: 0,
        stop: 25000,
        shuffle: True,
        center: True,
    },
    model: !obj:pylearn2.models.mlp.MLP {
        layers: [
                 !obj:pylearn2.models.mlp.Sigmoid {
                     layer_name: 'h0',
                     dim: 500,
                     sparse_init: 15,
                 }, !obj:pylearn2.models.mlp.Softmax {
                     layer_name: 'y',
                     n_classes: 121,
                     irange: 0.
                 }
                ],
        nvis: 1024,
    },
    algorithm: !obj:pylearn2.training_algorithms.bgd.BGD {
        batch_size: 5000,
        line_search_mode: 'exhaustive',
        conjugate: 1,
        updates_per_batch: 10,
        monitoring_dataset:
            {
                'train' : *train,
                'valid' : !obj:pylearn2.datasets.datascibowl.DataSciBowl {
                              which_set: 'train',
                              start: 25000,
                              stop:  30000,
                              shuffle: True,
                              center: True
                          }
            },
        termination_criterion: !obj:pylearn2.termination_criteria.And {
            criteria: [
                !obj:pylearn2.termination_criteria.MonitorBased {
                    channel_name: "valid_y_nll"
                },
                !obj:pylearn2.termination_criteria.EpochCounter {
                    max_epochs: 10000
                }
            ]
        }
    },
    extensions: [
        !obj:pylearn2.train_extensions.best_params.MonitorBasedSaveBest {
             channel_name: 'valid_y_nll',
             save_path: "mlp_01_best.pkl"
        }
    ],
}
#+END_SRC

Score still bad, 8.xx. CNN should provide a substantial
improvement.

*** DONE Research on CNN application
    CLOSED: [2015-02-25 Wed 19:38]
    :LOGBOOK:  
    - State "DONE"       from ""           [2015-02-25 Wed 19:38]
    :END:      
    See [[http://www.cs.toronto.edu/~fritz/absps/imagenet.pdf][krizhevsky et al]]
    - [[http://ufldl.stanford.edu/wiki/index.php/Softmax_Regression][Here]] is a good wiki on softmax
      - it's use is for mutually exclusive multiclass problems
      - in the 2 class problem it simplifies to logistic regression
    - The parameters are learned by optimizing the cost
      function using an itertive algorithm, such as gradient
      descent. Note that such an optimization algorithm can
      be used for many cost functions, such as those applying
      to K-means, SVM, Lasso.
      - the cost function for softmax with weight decay, is
       	some equation
      - [[http://research.microsoft.com/pubs/192769/tricks-2012.pdf][bottou]] provides some good info on SGD
       	- it should be used when training time is the bottleneck
      - [[http://leon.bottou.org/slides/largescale/lstut.pdf][more from bottou]], SGD with mnist as example
    - Convolutional layers?
    - Kernals and neurons?
    - Dropout
    - softmax params
      - We trained our models using stochastic gradient
       	descent with a batch size of 128 examples, momentum
       	of 0.9, and weight decay of 0.0005.
    - 

*** NEXT then cnn
    :LOGBOOK:  
    - State "NEXT"       from ""           [2015-02-25 Wed 19:38]
    :END:      
    - http://deeplearning.net/tutorial/lenet.html great explanation
    - http://localhost:8888/notebooks/pylearn2_fork/pylearn2/scripts/tutorials/convolutional_network/convolutional_network.ipynb
    - example settings
      - https://groups.google.com/forum/#!topic/pylearn-users/ZVbIQGh0YMQ
    - CNN is simply MLP with slight translation invariance
    - this is good for our image recognition problem
    - this is set up similar to MLP, but we use
      'input_space' instead of 'nvis', which preserves
      topological significance. nvis is shorthand for
      vectorspace(n), i.e. right now my images are being
      converted to vector representation! humbug
    - the yaml setup file in the CNN tutorial is useful to
      refer to,
      - conv rectified layers are used
      - and 

#+begin_src sh :results verbatim code replace output 
cat ipynb_work/cnn_01.yaml
#+end_src

** TODO [#B] Profile GPU
   - [[http://www.google.com/url?q=http%3A%2F%2Fdeeplearning.net%2Fsoftware%2Ftheano%2Ftutorial%2Fprofiling.html%23tut-profiling&sa=D&sntz=1&usg=AFQjCNHl7kjDxkJo5OPK0LFWqlt7ESX2Rw][link]]

** TODO [#B] Tune GPU
   :LOGBOOK:  
   - State "NEXT"       from ""           [2015-02-23 Mon 22:05]
   :END:      
It seems slow with BGD but fast with SGD.

See [[https://groups.google.com/forum/#!searchin/pylearn-users/GPU/pylearn-users/YzQ4S1agOCo/3o2pQHXfsp4J][this thread]]. And [[https://groups.google.com/forum/#!searchin/pylearn-users/GPU/pylearn-users/DDLbwJLw69Y/mOKi6-XEY4wJ][that one]]. Finally, [[https://groups.google.com/forum/#!searchin/pylearn-users/GPU/pylearn-users/yj3BoLlhouU/hq3H1ZXqdeIJ][this one]] may also
help.

Get the bleeding edge theano.
#+begin_src sh :noeval
pip uninstall theano
pip install --upgrade --no-deps git+git://github.com/Theano/Theano.git
#+end_src

Try adding this to .theanorc. It will confirm that gpu
is working. Two, it offers a speedup.

#+begin_src 
allow_gc = False
#+end_src

Try ('c', 1, 0, 'b') axis order.

** TODO [#B] parameter tuning
   -
** TODO [#C] other stopping riles
   - epochs
   - other monitor costs
** TODO [#C] Even obs per class?
   :LOGBOOK:  
   - State "NEXT"       from ""           [2015-02-16 Mon 11:41]
   :END:      
** TODO [#C] Remove the unnecessary reshapes
   :LOGBOOK:  
   - State "NEXT"       from ""           [2015-02-16 Mon 10:06]
   :END:      
   - also test reshape
   - does
     | A | A | A |
     | B | B | B |
     reshape(6,1) become
     | A | A | A | B | B | B |
     and that reshape(3,2) become
     | A | A | A |
     | B | B | B |
     ?

** TODO [#C] Thresholded observations?
   :LOGBOOK:  
   - State "NEXT"       from ""           [2015-02-16 Mon 11:11]
   :END:      
   - I thought softmax didn't learn 0 and 1 well, this
     should perform poorly
** TODO [#C] Compare time to read images vs load h5 file
   - see [[Saving large pickle/h5]]
** [[http://daemonmaker.blogspot.ca/2014/10/a-first-experiment-with-pylearn2.html][Pylearn2 models]] and [[http://deeplearning.net/software/pylearn2/library/index.html#libdoc][official docs]]
   - algorithm
     - bgd
       - batch size
	 - Setting this to 1 results in pure stochastic gradient
	   descent whereas setting it to the size of the
	   training set effectively results in batch gradient
	   descent.
   - softmax parameters
     - batch
     - irange
** TODO Understand the fitting monitor
   :LOGBOOK:  
   - State "NEXT"       from ""           [2015-02-15 Sun 22:14]
   :END:      
   The fitting monitor gives some information that should be
   understood. Here's helpful [[http://daemonmaker.blogspot.ca/2014/12/monitoring-experiments-in-pylearn2.html][link]]
#+begin_src python :noeval
Monitoring step:
	Epochs seen: 3
	Batches seen: 15
	Examples seen: 75000
	ave_grad_mult: 0.0497610855166
	ave_grad_size: 1.33559131637
	ave_step_size: 0.0652578686429
	total_seconds_last_epoch: 410.991061
	train_objective: 3.63486511009
	train_y_col_norms_max: 0.743025824372
	train_y_col_norms_mean: 0.17295732139
	train_y_col_norms_min: 0.0269976684984
	train_y_max_max_class: 0.48181040514
	train_y_mean_max_class: 0.0885340497259
	train_y_min_max_class: 0.0411385993209
	train_y_misclass: 0.8402
	train_y_nll: 3.63486511009
	train_y_row_norms_max: 0.270664018449
	train_y_row_norms_mean: 0.066049282967
	train_y_row_norms_min: 0.0319228798405
	training_seconds_this_epoch: 400.303218
#+end_src

   ~epochs~

   ~batches~

   ~examples~

   ~ave_grad~
       ~mult~
       ~size~
   
   ~ave_step_size~

   ~objective~

   ~train_y_~
       ~col|row_norms_~
           ~max~
           ~mean~
           ~min~
        ~max_max_class~
	~mean_max_class~
	~min_max_class~
	~misclass~
	~nll~

** TODO full batch size
   -https://groups.google.com/forum/#!topic/pylearn-users/kM1PDr0jlm8
** TODO Fit more models/Combinations to try
   :LOGBOOK:  
   - State "NEXT"       from ""           [2015-02-15 Sun 22:14]
   :END:      
   - parameter space
     - how to save performance vs. settings
   - model
   - algorithm
   - data augmentation
